{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(4444)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>dataset_n</th>\n",
       "      <th>train_val_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R1509261.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>보 도 자 료\\nhttp://www.msip.go.kr 보도일시 2015. 9. 4...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R2003733.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>보도일시 2020. 3. 18.(수) 조간(온라인 3. 17. 12:00)부터 보도...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D1507076-1.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>보 도 자 료\\nhttp://www.msip.go.kr 보도일시 2015. 7. 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R2005031.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>보 도 자 료\\n배포일시 2020. 4. 29.(수) 총 4매(본문2) 담당 부서 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R2006226.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;전매체&gt; 2020년 6월 3일(수) 10:00(국무회의 개최시)부터 보도하여 주시...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file_name  label                                           raw_text  \\\n",
       "0    R1509261.txt      0  보 도 자 료\\nhttp://www.msip.go.kr 보도일시 2015. 9. 4...   \n",
       "1    R2003733.txt      0  보도일시 2020. 3. 18.(수) 조간(온라인 3. 17. 12:00)부터 보도...   \n",
       "2  D1507076-1.txt      0  보 도 자 료\\nhttp://www.msip.go.kr 보도일시 2015. 7. 1...   \n",
       "3    R2005031.txt      0  보 도 자 료\\n배포일시 2020. 4. 29.(수) 총 4매(본문2) 담당 부서 ...   \n",
       "4    R2006226.txt      0  <전매체> 2020년 6월 3일(수) 10:00(국무회의 개최시)부터 보도하여 주시...   \n",
       "\n",
       "   dataset_n  train_val_test  \n",
       "0          0               0  \n",
       "1          0               0  \n",
       "2          0               0  \n",
       "3          0               0  \n",
       "4          0               0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../../../../jaeyeun/01_nh_poc/15_split_data_set_and_make_json_for_train_test_set/split_70_15_15.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train : KDI 70+15 (train+val)\n",
    "* Val : KDI 15(test)\n",
    "* Test : legal 273(train+val+test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = df[(df['dataset_n'] == 0) & ((df['train_val_test'] == 0) | (df['train_val_test'] == 1))]\n",
    "X_val_df = df[(df['dataset_n'] == 0) & (df['train_val_test'] == 2)]\n",
    "X_test_df = df[df['dataset_n'] != 0]\n",
    "y_train = df[(df['dataset_n'] == 0) & ((df['train_val_test'] == 0) | (df['train_val_test'] == 1))]['label']\n",
    "y_val = df[(df['dataset_n'] == 0) & (df['train_val_test'] == 2)]['label']\n",
    "y_test = df[df['dataset_n'] != 0]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9174, 5)\n",
      "(1626, 5)\n",
      "(273, 5)\n",
      "(9174,)\n",
      "(1626,)\n",
      "(273,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_df.shape)\n",
    "print(X_val_df.shape)\n",
    "print(X_test_df.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 100000\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_df=0.9, # 0.9 만큼의 문서 이상에서 나오면 거른다.\n",
    "    min_df=5, # 5개 미만의 문서에서 나오면 거른다.\n",
    "    sublinear_tf = True, # tf value를 완만하게 처리 (outlier 처리 효과)\n",
    "#     ngram_range = (1, 3),\n",
    "    max_features=n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf_vectorizer.fit(X_train_df['raw_text'])\n",
    "# X_test_tfidf = tfidf_vectorizer.fit_transform(prep_text_test)\n",
    "# X_test_hash = hash_vectorizer.fit_transform(prep_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf_transformed = X_train_tfidf.transform(X_train_df['raw_text'])\n",
    "X_val_tfidf_transformed = X_train_tfidf.transform(X_val_df['raw_text'])\n",
    "X_test_tfidf_transformed = X_train_tfidf.transform(X_test_df['raw_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9174, 96971)\n",
      "(1626, 96971)\n",
      "(273, 96971)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tfidf_transformed.shape)\n",
    "print(X_val_tfidf_transformed.shape)\n",
    "print(X_test_tfidf_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(n_components=1000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=1000)\n",
    "svd.fit(X_train_tfidf_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = svd.transform(X_train_tfidf_transformed)\n",
    "X_val = svd.transform(X_val_tfidf_transformed)\n",
    "X_test = svd.transform(X_test_tfidf_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9174, 1000)\n",
      "(1626, 1000)\n",
      "(273, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* LightGBM RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 16.2min\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of 100 | elapsed: 22.1min remaining: 24.0min\n",
      "[Parallel(n_jobs=-1)]: Done  59 out of 100 | elapsed: 25.9min remaining: 18.0min\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of 100 | elapsed: 29.8min remaining: 12.8min\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of 100 | elapsed: 34.7min remaining:  8.1min\n",
      "[Parallel(n_jobs=-1)]: Done  92 out of 100 | elapsed: 37.3min remaining:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 39.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's multi_error: 0.490735\ttraining's multi_logloss: 1.99096\tvalid_1's multi_error: 0.49877\tvalid_1's multi_logloss: 2.01396\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttraining's multi_error: 0.313168\ttraining's multi_logloss: 1.80062\tvalid_1's multi_error: 0.367159\tvalid_1's multi_logloss: 1.84469\n",
      "[3]\ttraining's multi_error: 0.245258\ttraining's multi_logloss: 1.64734\tvalid_1's multi_error: 0.311193\tvalid_1's multi_logloss: 1.71122\n",
      "[4]\ttraining's multi_error: 0.214846\ttraining's multi_logloss: 1.52048\tvalid_1's multi_error: 0.279213\tvalid_1's multi_logloss: 1.6014\n",
      "[5]\ttraining's multi_error: 0.194245\ttraining's multi_logloss: 1.41169\tvalid_1's multi_error: 0.266298\tvalid_1's multi_logloss: 1.50947\n",
      "[6]\ttraining's multi_error: 0.180183\ttraining's multi_logloss: 1.3162\tvalid_1's multi_error: 0.253998\tvalid_1's multi_logloss: 1.42649\n",
      "[7]\ttraining's multi_error: 0.169719\ttraining's multi_logloss: 1.23203\tvalid_1's multi_error: 0.242927\tvalid_1's multi_logloss: 1.35582\n",
      "[8]\ttraining's multi_error: 0.16198\ttraining's multi_logloss: 1.15628\tvalid_1's multi_error: 0.237392\tvalid_1's multi_logloss: 1.29417\n",
      "[9]\ttraining's multi_error: 0.152605\ttraining's multi_logloss: 1.0889\tvalid_1's multi_error: 0.234932\tvalid_1's multi_logloss: 1.23923\n",
      "[10]\ttraining's multi_error: 0.144866\ttraining's multi_logloss: 1.02782\tvalid_1's multi_error: 0.228167\tvalid_1's multi_logloss: 1.19009\n",
      "[11]\ttraining's multi_error: 0.137454\ttraining's multi_logloss: 0.971564\tvalid_1's multi_error: 0.228782\tvalid_1's multi_logloss: 1.14591\n",
      "[12]\ttraining's multi_error: 0.132876\ttraining's multi_logloss: 0.921528\tvalid_1's multi_error: 0.226322\tvalid_1's multi_logloss: 1.10612\n",
      "[13]\ttraining's multi_error: 0.129496\ttraining's multi_logloss: 0.875278\tvalid_1's multi_error: 0.225707\tvalid_1's multi_logloss: 1.07183\n",
      "[14]\ttraining's multi_error: 0.125136\ttraining's multi_logloss: 0.832533\tvalid_1's multi_error: 0.225092\tvalid_1's multi_logloss: 1.03934\n",
      "[15]\ttraining's multi_error: 0.122084\ttraining's multi_logloss: 0.7927\tvalid_1's multi_error: 0.222632\tvalid_1's multi_logloss: 1.00886\n",
      "[16]\ttraining's multi_error: 0.119904\ttraining's multi_logloss: 0.756532\tvalid_1's multi_error: 0.222017\tvalid_1's multi_logloss: 0.981666\n",
      "[17]\ttraining's multi_error: 0.115653\ttraining's multi_logloss: 0.722735\tvalid_1's multi_error: 0.221402\tvalid_1's multi_logloss: 0.958519\n",
      "[18]\ttraining's multi_error: 0.111293\ttraining's multi_logloss: 0.690922\tvalid_1's multi_error: 0.221402\tvalid_1's multi_logloss: 0.934804\n",
      "[19]\ttraining's multi_error: 0.107478\ttraining's multi_logloss: 0.66096\tvalid_1's multi_error: 0.218327\tvalid_1's multi_logloss: 0.912232\n",
      "[20]\ttraining's multi_error: 0.103881\ttraining's multi_logloss: 0.632432\tvalid_1's multi_error: 0.217712\tvalid_1's multi_logloss: 0.893348\n",
      "[21]\ttraining's multi_error: 0.100828\ttraining's multi_logloss: 0.605828\tvalid_1's multi_error: 0.216482\tvalid_1's multi_logloss: 0.873856\n",
      "[22]\ttraining's multi_error: 0.0964683\ttraining's multi_logloss: 0.580939\tvalid_1's multi_error: 0.215252\tvalid_1's multi_logloss: 0.856954\n",
      "[23]\ttraining's multi_error: 0.0933072\ttraining's multi_logloss: 0.557946\tvalid_1's multi_error: 0.212177\tvalid_1's multi_logloss: 0.840693\n",
      "[24]\ttraining's multi_error: 0.0903641\ttraining's multi_logloss: 0.536114\tvalid_1's multi_error: 0.211562\tvalid_1's multi_logloss: 0.828328\n",
      "[25]\ttraining's multi_error: 0.0862219\ttraining's multi_logloss: 0.515779\tvalid_1's multi_error: 0.211562\tvalid_1's multi_logloss: 0.815212\n",
      "[26]\ttraining's multi_error: 0.0840419\ttraining's multi_logloss: 0.496368\tvalid_1's multi_error: 0.210947\tvalid_1's multi_logloss: 0.802686\n",
      "[27]\ttraining's multi_error: 0.0813168\ttraining's multi_logloss: 0.478026\tvalid_1's multi_error: 0.212177\tvalid_1's multi_logloss: 0.791616\n",
      "[28]\ttraining's multi_error: 0.0796817\ttraining's multi_logloss: 0.460674\tvalid_1's multi_error: 0.212177\tvalid_1's multi_logloss: 0.780414\n",
      "[29]\ttraining's multi_error: 0.0765206\ttraining's multi_logloss: 0.444395\tvalid_1's multi_error: 0.213407\tvalid_1's multi_logloss: 0.770072\n",
      "[30]\ttraining's multi_error: 0.0736865\ttraining's multi_logloss: 0.428503\tvalid_1's multi_error: 0.211562\tvalid_1's multi_logloss: 0.760558\n",
      "[31]\ttraining's multi_error: 0.0696534\ttraining's multi_logloss: 0.413577\tvalid_1's multi_error: 0.209717\tvalid_1's multi_logloss: 0.752199\n",
      "[32]\ttraining's multi_error: 0.0674733\ttraining's multi_logloss: 0.398809\tvalid_1's multi_error: 0.207872\tvalid_1's multi_logloss: 0.743486\n",
      "[33]\ttraining's multi_error: 0.0659472\ttraining's multi_logloss: 0.385835\tvalid_1's multi_error: 0.207872\tvalid_1's multi_logloss: 0.736017\n",
      "[34]\ttraining's multi_error: 0.0632221\ttraining's multi_logloss: 0.372283\tvalid_1's multi_error: 0.205412\tvalid_1's multi_logloss: 0.728655\n",
      "[35]\ttraining's multi_error: 0.0610421\ttraining's multi_logloss: 0.35933\tvalid_1's multi_error: 0.205412\tvalid_1's multi_logloss: 0.721887\n",
      "[36]\ttraining's multi_error: 0.058862\ttraining's multi_logloss: 0.347653\tvalid_1's multi_error: 0.206027\tvalid_1's multi_logloss: 0.715217\n",
      "[37]\ttraining's multi_error: 0.0570089\ttraining's multi_logloss: 0.336187\tvalid_1's multi_error: 0.205412\tvalid_1's multi_logloss: 0.70859\n",
      "[38]\ttraining's multi_error: 0.0546109\ttraining's multi_logloss: 0.325092\tvalid_1's multi_error: 0.202337\tvalid_1's multi_logloss: 0.702467\n",
      "[39]\ttraining's multi_error: 0.0523218\ttraining's multi_logloss: 0.315341\tvalid_1's multi_error: 0.202337\tvalid_1's multi_logloss: 0.697786\n",
      "[40]\ttraining's multi_error: 0.0492697\ttraining's multi_logloss: 0.304625\tvalid_1's multi_error: 0.202337\tvalid_1's multi_logloss: 0.693005\n",
      "[41]\ttraining's multi_error: 0.0456726\ttraining's multi_logloss: 0.295019\tvalid_1's multi_error: 0.202952\tvalid_1's multi_logloss: 0.688213\n",
      "[42]\ttraining's multi_error: 0.0439285\ttraining's multi_logloss: 0.285316\tvalid_1's multi_error: 0.203567\tvalid_1's multi_logloss: 0.683054\n",
      "[43]\ttraining's multi_error: 0.0407674\ttraining's multi_logloss: 0.275927\tvalid_1's multi_error: 0.202337\tvalid_1's multi_logloss: 0.679445\n",
      "[44]\ttraining's multi_error: 0.0385873\ttraining's multi_logloss: 0.267282\tvalid_1's multi_error: 0.201107\tvalid_1's multi_logloss: 0.675995\n",
      "[45]\ttraining's multi_error: 0.0366252\ttraining's multi_logloss: 0.258678\tvalid_1's multi_error: 0.201107\tvalid_1's multi_logloss: 0.673126\n",
      "[46]\ttraining's multi_error: 0.0348812\ttraining's multi_logloss: 0.250528\tvalid_1's multi_error: 0.201722\tvalid_1's multi_logloss: 0.668581\n",
      "[47]\ttraining's multi_error: 0.0328101\ttraining's multi_logloss: 0.24297\tvalid_1's multi_error: 0.198647\tvalid_1's multi_logloss: 0.665134\n",
      "[48]\ttraining's multi_error: 0.030521\ttraining's multi_logloss: 0.235389\tvalid_1's multi_error: 0.199877\tvalid_1's multi_logloss: 0.662495\n",
      "[49]\ttraining's multi_error: 0.029104\ttraining's multi_logloss: 0.227787\tvalid_1's multi_error: 0.194957\tvalid_1's multi_logloss: 0.660117\n",
      "[50]\ttraining's multi_error: 0.0265969\ttraining's multi_logloss: 0.220376\tvalid_1's multi_error: 0.196187\tvalid_1's multi_logloss: 0.657493\n",
      "[51]\ttraining's multi_error: 0.0250709\ttraining's multi_logloss: 0.213516\tvalid_1's multi_error: 0.193112\tvalid_1's multi_logloss: 0.653709\n",
      "[52]\ttraining's multi_error: 0.0229998\ttraining's multi_logloss: 0.207302\tvalid_1's multi_error: 0.193112\tvalid_1's multi_logloss: 0.651661\n",
      "[53]\ttraining's multi_error: 0.0222368\ttraining's multi_logloss: 0.201275\tvalid_1's multi_error: 0.188807\tvalid_1's multi_logloss: 0.648241\n",
      "[54]\ttraining's multi_error: 0.0208197\ttraining's multi_logloss: 0.19556\tvalid_1's multi_error: 0.188192\tvalid_1's multi_logloss: 0.645945\n",
      "[55]\ttraining's multi_error: 0.0189666\ttraining's multi_logloss: 0.189667\tvalid_1's multi_error: 0.188192\tvalid_1's multi_logloss: 0.643643\n",
      "[56]\ttraining's multi_error: 0.0177676\ttraining's multi_logloss: 0.183997\tvalid_1's multi_error: 0.188807\tvalid_1's multi_logloss: 0.641507\n",
      "[57]\ttraining's multi_error: 0.0160235\ttraining's multi_logloss: 0.178609\tvalid_1's multi_error: 0.189422\tvalid_1's multi_logloss: 0.640301\n",
      "[58]\ttraining's multi_error: 0.0147155\ttraining's multi_logloss: 0.173532\tvalid_1's multi_error: 0.186962\tvalid_1's multi_logloss: 0.6378\n",
      "[59]\ttraining's multi_error: 0.0136255\ttraining's multi_logloss: 0.168507\tvalid_1's multi_error: 0.188192\tvalid_1's multi_logloss: 0.63608\n",
      "[60]\ttraining's multi_error: 0.0123174\ttraining's multi_logloss: 0.163533\tvalid_1's multi_error: 0.188192\tvalid_1's multi_logloss: 0.633983\n",
      "[61]\ttraining's multi_error: 0.0114454\ttraining's multi_logloss: 0.158973\tvalid_1's multi_error: 0.188192\tvalid_1's multi_logloss: 0.632428\n",
      "[62]\ttraining's multi_error: 0.0105734\ttraining's multi_logloss: 0.154363\tvalid_1's multi_error: 0.189422\tvalid_1's multi_logloss: 0.631401\n",
      "[63]\ttraining's multi_error: 0.0100283\ttraining's multi_logloss: 0.150204\tvalid_1's multi_error: 0.187577\tvalid_1's multi_logloss: 0.629407\n",
      "[64]\ttraining's multi_error: 0.00904731\ttraining's multi_logloss: 0.145997\tvalid_1's multi_error: 0.186347\tvalid_1's multi_logloss: 0.628024\n",
      "[65]\ttraining's multi_error: 0.00839329\ttraining's multi_logloss: 0.141937\tvalid_1's multi_error: 0.188807\tvalid_1's multi_logloss: 0.626879\n",
      "[66]\ttraining's multi_error: 0.00763026\ttraining's multi_logloss: 0.138067\tvalid_1's multi_error: 0.186347\tvalid_1's multi_logloss: 0.625401\n",
      "[67]\ttraining's multi_error: 0.00730325\ttraining's multi_logloss: 0.134569\tvalid_1's multi_error: 0.186347\tvalid_1's multi_logloss: 0.623994\n",
      "[68]\ttraining's multi_error: 0.00675823\ttraining's multi_logloss: 0.130943\tvalid_1's multi_error: 0.185117\tvalid_1's multi_logloss: 0.622414\n",
      "[69]\ttraining's multi_error: 0.0057772\ttraining's multi_logloss: 0.127471\tvalid_1's multi_error: 0.186347\tvalid_1's multi_logloss: 0.621772\n",
      "[70]\ttraining's multi_error: 0.00545019\ttraining's multi_logloss: 0.124039\tvalid_1's multi_error: 0.186962\tvalid_1's multi_logloss: 0.620969\n",
      "[71]\ttraining's multi_error: 0.00512317\ttraining's multi_logloss: 0.12072\tvalid_1's multi_error: 0.185732\tvalid_1's multi_logloss: 0.619815\n",
      "[72]\ttraining's multi_error: 0.00479616\ttraining's multi_logloss: 0.117475\tvalid_1's multi_error: 0.185732\tvalid_1's multi_logloss: 0.618611\n",
      "[73]\ttraining's multi_error: 0.00425114\ttraining's multi_logloss: 0.114462\tvalid_1's multi_error: 0.186962\tvalid_1's multi_logloss: 0.617583\n",
      "[74]\ttraining's multi_error: 0.00359712\ttraining's multi_logloss: 0.111413\tvalid_1's multi_error: 0.185732\tvalid_1's multi_logloss: 0.616641\n",
      "[75]\ttraining's multi_error: 0.00316111\ttraining's multi_logloss: 0.108535\tvalid_1's multi_error: 0.185117\tvalid_1's multi_logloss: 0.616373\n",
      "[76]\ttraining's multi_error: 0.0030521\ttraining's multi_logloss: 0.105995\tvalid_1's multi_error: 0.184502\tvalid_1's multi_logloss: 0.61484\n",
      "[77]\ttraining's multi_error: 0.0029431\ttraining's multi_logloss: 0.103319\tvalid_1's multi_error: 0.183272\tvalid_1's multi_logloss: 0.613964\n",
      "[78]\ttraining's multi_error: 0.00272509\ttraining's multi_logloss: 0.100769\tvalid_1's multi_error: 0.184502\tvalid_1's multi_logloss: 0.613231\n",
      "[79]\ttraining's multi_error: 0.00239808\ttraining's multi_logloss: 0.098237\tvalid_1's multi_error: 0.182042\tvalid_1's multi_logloss: 0.612571\n",
      "[80]\ttraining's multi_error: 0.00218007\ttraining's multi_logloss: 0.0957017\tvalid_1's multi_error: 0.181427\tvalid_1's multi_logloss: 0.612044\n",
      "[81]\ttraining's multi_error: 0.00185306\ttraining's multi_logloss: 0.0934113\tvalid_1's multi_error: 0.181427\tvalid_1's multi_logloss: 0.611452\n",
      "[82]\ttraining's multi_error: 0.00174406\ttraining's multi_logloss: 0.0910908\tvalid_1's multi_error: 0.181427\tvalid_1's multi_logloss: 0.611275\n",
      "[83]\ttraining's multi_error: 0.00141705\ttraining's multi_logloss: 0.0888369\tvalid_1's multi_error: 0.182042\tvalid_1's multi_logloss: 0.610734\n",
      "[84]\ttraining's multi_error: 0.00119904\ttraining's multi_logloss: 0.0866632\tvalid_1's multi_error: 0.182657\tvalid_1's multi_logloss: 0.609568\n",
      "[85]\ttraining's multi_error: 0.00119904\ttraining's multi_logloss: 0.0845959\tvalid_1's multi_error: 0.181427\tvalid_1's multi_logloss: 0.608507\n",
      "[86]\ttraining's multi_error: 0.00119904\ttraining's multi_logloss: 0.0827151\tvalid_1's multi_error: 0.183272\tvalid_1's multi_logloss: 0.607844\n",
      "[87]\ttraining's multi_error: 0.00119904\ttraining's multi_logloss: 0.0807895\tvalid_1's multi_error: 0.182042\tvalid_1's multi_logloss: 0.607096\n",
      "[88]\ttraining's multi_error: 0.00109004\ttraining's multi_logloss: 0.0788962\tvalid_1's multi_error: 0.180197\tvalid_1's multi_logloss: 0.606407\n",
      "[89]\ttraining's multi_error: 0.00109004\ttraining's multi_logloss: 0.0772349\tvalid_1's multi_error: 0.180197\tvalid_1's multi_logloss: 0.605719\n",
      "[90]\ttraining's multi_error: 0.00109004\ttraining's multi_logloss: 0.0753981\tvalid_1's multi_error: 0.181427\tvalid_1's multi_logloss: 0.60557\n",
      "[91]\ttraining's multi_error: 0.00109004\ttraining's multi_logloss: 0.0737531\tvalid_1's multi_error: 0.180197\tvalid_1's multi_logloss: 0.605712\n",
      "[92]\ttraining's multi_error: 0.00109004\ttraining's multi_logloss: 0.072184\tvalid_1's multi_error: 0.182042\tvalid_1's multi_logloss: 0.605528\n",
      "[93]\ttraining's multi_error: 0.00087203\ttraining's multi_logloss: 0.0705606\tvalid_1's multi_error: 0.180812\tvalid_1's multi_logloss: 0.605262\n",
      "[94]\ttraining's multi_error: 0.00087203\ttraining's multi_logloss: 0.0691221\tvalid_1's multi_error: 0.180812\tvalid_1's multi_logloss: 0.604644\n",
      "[95]\ttraining's multi_error: 0.00087203\ttraining's multi_logloss: 0.0676498\tvalid_1's multi_error: 0.181427\tvalid_1's multi_logloss: 0.604064\n",
      "[96]\ttraining's multi_error: 0.00087203\ttraining's multi_logloss: 0.0663688\tvalid_1's multi_error: 0.180197\tvalid_1's multi_logloss: 0.604007\n",
      "[97]\ttraining's multi_error: 0.00087203\ttraining's multi_logloss: 0.065053\tvalid_1's multi_error: 0.178352\tvalid_1's multi_logloss: 0.602894\n",
      "[98]\ttraining's multi_error: 0.00087203\ttraining's multi_logloss: 0.0637364\tvalid_1's multi_error: 0.178967\tvalid_1's multi_logloss: 0.603042\n",
      "[99]\ttraining's multi_error: 0.00087203\ttraining's multi_logloss: 0.0624519\tvalid_1's multi_error: 0.178352\tvalid_1's multi_logloss: 0.602857\n",
      "[100]\ttraining's multi_error: 0.00087203\ttraining's multi_logloss: 0.0611705\tvalid_1's multi_error: 0.177737\tvalid_1's multi_logloss: 0.602786\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[93]\ttraining's multi_error: 0.00087203\ttraining's multi_logloss: 0.0705606\tvalid_1's multi_error: 0.180812\tvalid_1's multi_logloss: 0.605262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=LGBMClassifier(), n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': [0.01, 0.015, 0.025,\n",
       "                                                          0.05, 0.1],\n",
       "                                        'max_depth': [3, 5, 7, 9, 12, 15, 17,\n",
       "                                                      25],\n",
       "                                        'min_child_weight': [1, 3, 5, 7],\n",
       "                                        'subsample': array([0.6, 0.7, 0.8, 0.9, 1. ])},\n",
       "                   return_train_score=True, scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_clf = lgbm.LGBMClassifier()\n",
    "\n",
    "lgbm_param_grid = {'learning_rate': [.01, .015, .025, .05, .1],\n",
    "#                   'Gamma': [.05, .1, .3, .5, .7, .9, 1],\n",
    "                  'max_depth': [3, 5, 7, 9, 12, 15, 17, 25],\n",
    "                  'min_child_weight': [1, 3, 5, 7],\n",
    "                  'subsample': np.linspace(0.6, 1, 5)}\n",
    "\n",
    "fit_params = {\"early_stopping_rounds\" : 20,\n",
    "             \"eval_metric\" : \"multi_error\",\n",
    "             \"eval_set\" : [(X_train, y_train), (X_val, y_val)]}\n",
    "\n",
    "# Create a random search object\n",
    "lgbm_random = RandomizedSearchCV(estimator = lgbm_clf,\n",
    "                                param_distributions = lgbm_param_grid,\n",
    "                                n_iter = 20, # n_iters in param combinations\n",
    "                                scoring='accuracy',\n",
    "                                n_jobs=-1,\n",
    "                                cv = 5,\n",
    "                                refit=True,\n",
    "                                return_train_score = True,\n",
    "                                verbose=10)\n",
    "\n",
    "# Fit to the training data\n",
    "lgbm_random.fit(X_train, y_train, **fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = lgbm_random.best_estimator_.predict(X_train)\n",
    "pred_val = lgbm_random.best_estimator_.predict(X_val)\n",
    "pred_test = lgbm_random.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9991279703509919\n",
      "0.8191881918819188\n",
      "0.16483516483516483\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_train, pred_train))\n",
    "print(accuracy_score(y_val, pred_val))\n",
    "print(accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(max_depth=7, min_child_weight=7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subsample</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.762481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.764007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.777523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.778395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.779704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.780358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.780685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.791476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.798561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.802268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.804665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.806736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.807282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.808262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.808263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.810334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.810443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.810660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.811205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.813386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subsample  min_child_weight  max_depth  learning_rate  mean_test_score\n",
       "0        1.0                 3          5          0.015         0.762481\n",
       "0        0.9                 1          7          0.010         0.764007\n",
       "0        0.7                 7         15          0.015         0.777523\n",
       "0        0.9                 7          5          0.025         0.778395\n",
       "0        0.8                 3         15          0.015         0.779704\n",
       "0        1.0                 3         17          0.015         0.780358\n",
       "0        1.0                 5         12          0.015         0.780685\n",
       "0        0.6                 3         12          0.025         0.791476\n",
       "0        0.6                 7          5          0.050         0.798561\n",
       "0        1.0                 3          7          0.050         0.802268\n",
       "0        0.9                 3         15          0.050         0.804665\n",
       "0        0.6                 1          5          0.100         0.806736\n",
       "0        0.6                 5          7          0.100         0.807282\n",
       "0        0.9                 3          5          0.100         0.808262\n",
       "0        0.7                 5          9          0.100         0.808263\n",
       "0        0.6                 1          9          0.100         0.810334\n",
       "0        0.6                 3         25          0.100         0.810443\n",
       "0        0.6                 7         12          0.100         0.810660\n",
       "0        0.8                 7          9          0.100         0.811205\n",
       "0        1.0                 7          7          0.100         0.813386"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_df = pd.DataFrame(lgbm_random.cv_results_)\n",
    "\n",
    "df_list = []\n",
    "for i in range(20):\n",
    "    df_list.append(pd.DataFrame([cv_result_df.loc[i, \"params\"]]))\n",
    "    \n",
    "param_table = pd.concat(df_list)\n",
    "\n",
    "param_table['mean_test_score'] = cv_result_df['mean_test_score'].values\n",
    "\n",
    "param_table.sort_values(by='mean_test_score', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
