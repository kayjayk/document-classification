{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(4444)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>dataset_n</th>\n",
       "      <th>train_val_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R1509261.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>보 도 자 료\\nhttp://www.msip.go.kr 보도일시 2015. 9. 4...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R2003733.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>보도일시 2020. 3. 18.(수) 조간(온라인 3. 17. 12:00)부터 보도...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D1507076-1.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>보 도 자 료\\nhttp://www.msip.go.kr 보도일시 2015. 7. 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R2005031.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>보 도 자 료\\n배포일시 2020. 4. 29.(수) 총 4매(본문2) 담당 부서 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R2006226.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;전매체&gt; 2020년 6월 3일(수) 10:00(국무회의 개최시)부터 보도하여 주시...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file_name  label                                           raw_text  \\\n",
       "0    R1509261.txt      0  보 도 자 료\\nhttp://www.msip.go.kr 보도일시 2015. 9. 4...   \n",
       "1    R2003733.txt      0  보도일시 2020. 3. 18.(수) 조간(온라인 3. 17. 12:00)부터 보도...   \n",
       "2  D1507076-1.txt      0  보 도 자 료\\nhttp://www.msip.go.kr 보도일시 2015. 7. 1...   \n",
       "3    R2005031.txt      0  보 도 자 료\\n배포일시 2020. 4. 29.(수) 총 4매(본문2) 담당 부서 ...   \n",
       "4    R2006226.txt      0  <전매체> 2020년 6월 3일(수) 10:00(국무회의 개최시)부터 보도하여 주시...   \n",
       "\n",
       "   dataset_n  train_val_test  \n",
       "0          0               0  \n",
       "1          0               0  \n",
       "2          0               0  \n",
       "3          0               0  \n",
       "4          0               0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../../../../jaeyeun/01_nh_poc/15_split_data_set_and_make_json_for_train_test_set/split_70_15_15.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train : KDI 70+15 (train+val)\n",
    "* Val : KDI 15(test)\n",
    "* Test : legal 273(train+val+test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = df[(df['dataset_n'] == 0) & ((df['train_val_test'] == 0) | (df['train_val_test'] == 1))]\n",
    "X_val_df = df[(df['dataset_n'] == 0) & (df['train_val_test'] == 2)]\n",
    "X_test_df = df[df['dataset_n'] != 0]\n",
    "y_train = df[(df['dataset_n'] == 0) & ((df['train_val_test'] == 0) | (df['train_val_test'] == 1))]['label']\n",
    "y_val = df[(df['dataset_n'] == 0) & (df['train_val_test'] == 2)]['label']\n",
    "y_test = df[df['dataset_n'] != 0]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9174, 5)\n",
      "(1626, 5)\n",
      "(273, 5)\n",
      "(9174,)\n",
      "(1626,)\n",
      "(273,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_df.shape)\n",
    "print(X_val_df.shape)\n",
    "print(X_test_df.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 100000\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_df=0.9, # 0.9 만큼의 문서 이상에서 나오면 거른다.\n",
    "    min_df=5, # 5개 미만의 문서에서 나오면 거른다.\n",
    "    sublinear_tf = True, # tf value를 완만하게 처리 (outlier 처리 효과)\n",
    "    ngram_range = (1, 3),\n",
    "    max_features=n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf_vectorizer.fit(X_train_df['raw_text'])\n",
    "# X_test_tfidf = tfidf_vectorizer.fit_transform(prep_text_test)\n",
    "# X_test_hash = hash_vectorizer.fit_transform(prep_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_tfidf.transform(X_train_df['raw_text'])\n",
    "X_val = X_train_tfidf.transform(X_val_df['raw_text'])\n",
    "X_test = X_train_tfidf.transform(X_test_df['raw_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9174, 100000)\n",
      "(1626, 100000)\n",
      "(273, 100000)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(n_components=100)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=100)\n",
    "svd.fit(X_train_tfidf_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = svd.transform(X_train_tfidf_transformed)\n",
    "X_val = svd.transform(X_val_tfidf_transformed)\n",
    "X_test = svd.transform(X_test_tfidf_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9174, 100)\n",
      "(1626, 100)\n",
      "(273, 100)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* LightGBM RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:   39.6s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   51.7s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   59.1s\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of 100 | elapsed:  1.6min remaining:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  59 out of 100 | elapsed:  1.7min remaining:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of 100 | elapsed:  1.9min remaining:   47.8s\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of 100 | elapsed:  2.3min remaining:   32.6s\n",
      "[Parallel(n_jobs=-1)]: Done  92 out of 100 | elapsed:  2.4min remaining:   12.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's multi_error: 0.443536\ttraining's multi_logloss: 1.97441\tvalid_1's multi_error: 0.468635\tvalid_1's multi_logloss: 2.00179\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttraining's multi_error: 0.2845\ttraining's multi_logloss: 1.77681\tvalid_1's multi_error: 0.334563\tvalid_1's multi_logloss: 1.82763\n",
      "[3]\ttraining's multi_error: 0.226292\ttraining's multi_logloss: 1.62152\tvalid_1's multi_error: 0.290898\tvalid_1's multi_logloss: 1.692\n",
      "[4]\ttraining's multi_error: 0.194136\ttraining's multi_logloss: 1.4939\tvalid_1's multi_error: 0.259533\tvalid_1's multi_logloss: 1.58212\n",
      "[5]\ttraining's multi_error: 0.179965\ttraining's multi_logloss: 1.3851\tvalid_1's multi_error: 0.252768\tvalid_1's multi_logloss: 1.48936\n",
      "[6]\ttraining's multi_error: 0.168847\ttraining's multi_logloss: 1.29164\tvalid_1's multi_error: 0.240467\tvalid_1's multi_logloss: 1.40963\n",
      "[7]\ttraining's multi_error: 0.159908\ttraining's multi_logloss: 1.20844\tvalid_1's multi_error: 0.234317\tvalid_1's multi_logloss: 1.33982\n",
      "[8]\ttraining's multi_error: 0.153804\ttraining's multi_logloss: 1.13473\tvalid_1's multi_error: 0.229397\tvalid_1's multi_logloss: 1.27814\n",
      "[9]\ttraining's multi_error: 0.146719\ttraining's multi_logloss: 1.06887\tvalid_1's multi_error: 0.228167\tvalid_1's multi_logloss: 1.22402\n",
      "[10]\ttraining's multi_error: 0.14334\ttraining's multi_logloss: 1.00956\tvalid_1's multi_error: 0.222632\tvalid_1's multi_logloss: 1.17392\n",
      "[11]\ttraining's multi_error: 0.140288\ttraining's multi_logloss: 0.955915\tvalid_1's multi_error: 0.226322\tvalid_1's multi_logloss: 1.13119\n",
      "[12]\ttraining's multi_error: 0.135383\ttraining's multi_logloss: 0.906788\tvalid_1's multi_error: 0.223247\tvalid_1's multi_logloss: 1.09124\n",
      "[13]\ttraining's multi_error: 0.131894\ttraining's multi_logloss: 0.862193\tvalid_1's multi_error: 0.223247\tvalid_1's multi_logloss: 1.0556\n",
      "[14]\ttraining's multi_error: 0.127861\ttraining's multi_logloss: 0.821108\tvalid_1's multi_error: 0.218327\tvalid_1's multi_logloss: 1.02244\n",
      "[15]\ttraining's multi_error: 0.125027\ttraining's multi_logloss: 0.783032\tvalid_1's multi_error: 0.219557\tvalid_1's multi_logloss: 0.993194\n",
      "[16]\ttraining's multi_error: 0.123501\ttraining's multi_logloss: 0.747553\tvalid_1's multi_error: 0.217097\tvalid_1's multi_logloss: 0.966095\n",
      "[17]\ttraining's multi_error: 0.11925\ttraining's multi_logloss: 0.715084\tvalid_1's multi_error: 0.220172\tvalid_1's multi_logloss: 0.941979\n",
      "[18]\ttraining's multi_error: 0.116089\ttraining's multi_logloss: 0.684593\tvalid_1's multi_error: 0.217097\tvalid_1's multi_logloss: 0.917281\n",
      "[19]\ttraining's multi_error: 0.114999\ttraining's multi_logloss: 0.656514\tvalid_1's multi_error: 0.215867\tvalid_1's multi_logloss: 0.895713\n",
      "[20]\ttraining's multi_error: 0.110966\ttraining's multi_logloss: 0.629413\tvalid_1's multi_error: 0.213407\tvalid_1's multi_logloss: 0.876536\n",
      "[21]\ttraining's multi_error: 0.10835\ttraining's multi_logloss: 0.604458\tvalid_1's multi_error: 0.212177\tvalid_1's multi_logloss: 0.859184\n",
      "[22]\ttraining's multi_error: 0.105298\ttraining's multi_logloss: 0.580876\tvalid_1's multi_error: 0.211562\tvalid_1's multi_logloss: 0.841838\n",
      "[23]\ttraining's multi_error: 0.103118\ttraining's multi_logloss: 0.558503\tvalid_1's multi_error: 0.209717\tvalid_1's multi_logloss: 0.824543\n",
      "[24]\ttraining's multi_error: 0.101155\ttraining's multi_logloss: 0.537975\tvalid_1's multi_error: 0.206027\tvalid_1's multi_logloss: 0.809698\n",
      "[25]\ttraining's multi_error: 0.0977763\ttraining's multi_logloss: 0.51815\tvalid_1's multi_error: 0.206027\tvalid_1's multi_logloss: 0.796498\n",
      "[26]\ttraining's multi_error: 0.0953782\ttraining's multi_logloss: 0.499366\tvalid_1's multi_error: 0.205412\tvalid_1's multi_logloss: 0.783286\n",
      "[27]\ttraining's multi_error: 0.0923261\ttraining's multi_logloss: 0.481621\tvalid_1's multi_error: 0.204182\tvalid_1's multi_logloss: 0.771676\n",
      "[28]\ttraining's multi_error: 0.0899281\ttraining's multi_logloss: 0.465043\tvalid_1's multi_error: 0.204797\tvalid_1's multi_logloss: 0.76201\n",
      "[29]\ttraining's multi_error: 0.087203\ttraining's multi_logloss: 0.44923\tvalid_1's multi_error: 0.201107\tvalid_1's multi_logloss: 0.752303\n",
      "[30]\ttraining's multi_error: 0.0834968\ttraining's multi_logloss: 0.434031\tvalid_1's multi_error: 0.200492\tvalid_1's multi_logloss: 0.74278\n",
      "[31]\ttraining's multi_error: 0.0806627\ttraining's multi_logloss: 0.419266\tvalid_1's multi_error: 0.201107\tvalid_1's multi_logloss: 0.734337\n",
      "[32]\ttraining's multi_error: 0.0787007\ttraining's multi_logloss: 0.405391\tvalid_1's multi_error: 0.199877\tvalid_1's multi_logloss: 0.726038\n",
      "[33]\ttraining's multi_error: 0.0756486\ttraining's multi_logloss: 0.392029\tvalid_1's multi_error: 0.199262\tvalid_1's multi_logloss: 0.718586\n",
      "[34]\ttraining's multi_error: 0.0736865\ttraining's multi_logloss: 0.379413\tvalid_1's multi_error: 0.198032\tvalid_1's multi_logloss: 0.711865\n",
      "[35]\ttraining's multi_error: 0.0708524\ttraining's multi_logloss: 0.367344\tvalid_1's multi_error: 0.198647\tvalid_1's multi_logloss: 0.70557\n",
      "[36]\ttraining's multi_error: 0.0685633\ttraining's multi_logloss: 0.355885\tvalid_1's multi_error: 0.198032\tvalid_1's multi_logloss: 0.699683\n",
      "[37]\ttraining's multi_error: 0.0668193\ttraining's multi_logloss: 0.344681\tvalid_1's multi_error: 0.197417\tvalid_1's multi_logloss: 0.694032\n",
      "[38]\ttraining's multi_error: 0.0647482\ttraining's multi_logloss: 0.334086\tvalid_1's multi_error: 0.196802\tvalid_1's multi_logloss: 0.688665\n",
      "[39]\ttraining's multi_error: 0.0627861\ttraining's multi_logloss: 0.323617\tvalid_1's multi_error: 0.194957\tvalid_1's multi_logloss: 0.683359\n",
      "[40]\ttraining's multi_error: 0.059843\ttraining's multi_logloss: 0.313921\tvalid_1's multi_error: 0.197417\tvalid_1's multi_logloss: 0.678205\n",
      "[41]\ttraining's multi_error: 0.058535\ttraining's multi_logloss: 0.304547\tvalid_1's multi_error: 0.196187\tvalid_1's multi_logloss: 0.672964\n",
      "[42]\ttraining's multi_error: 0.0563549\ttraining's multi_logloss: 0.295371\tvalid_1's multi_error: 0.193727\tvalid_1's multi_logloss: 0.66802\n",
      "[43]\ttraining's multi_error: 0.0533028\ttraining's multi_logloss: 0.286748\tvalid_1's multi_error: 0.193727\tvalid_1's multi_logloss: 0.663599\n",
      "[44]\ttraining's multi_error: 0.0504687\ttraining's multi_logloss: 0.278517\tvalid_1's multi_error: 0.192497\tvalid_1's multi_logloss: 0.659824\n",
      "[45]\ttraining's multi_error: 0.0482886\ttraining's multi_logloss: 0.270057\tvalid_1's multi_error: 0.192497\tvalid_1's multi_logloss: 0.656107\n",
      "[46]\ttraining's multi_error: 0.0457816\ttraining's multi_logloss: 0.262188\tvalid_1's multi_error: 0.193727\tvalid_1's multi_logloss: 0.65215\n",
      "[47]\ttraining's multi_error: 0.0440375\ttraining's multi_logloss: 0.254538\tvalid_1's multi_error: 0.191267\tvalid_1's multi_logloss: 0.648705\n",
      "[48]\ttraining's multi_error: 0.0420754\ttraining's multi_logloss: 0.247161\tvalid_1's multi_error: 0.191267\tvalid_1's multi_logloss: 0.645124\n",
      "[49]\ttraining's multi_error: 0.0405494\ttraining's multi_logloss: 0.240105\tvalid_1's multi_error: 0.191267\tvalid_1's multi_logloss: 0.641962\n",
      "[50]\ttraining's multi_error: 0.0384783\ttraining's multi_logloss: 0.233136\tvalid_1's multi_error: 0.191267\tvalid_1's multi_logloss: 0.639602\n",
      "[51]\ttraining's multi_error: 0.0362982\ttraining's multi_logloss: 0.226708\tvalid_1's multi_error: 0.194342\tvalid_1's multi_logloss: 0.636736\n",
      "[52]\ttraining's multi_error: 0.0346632\ttraining's multi_logloss: 0.220248\tvalid_1's multi_error: 0.193112\tvalid_1's multi_logloss: 0.634099\n",
      "[53]\ttraining's multi_error: 0.0331371\ttraining's multi_logloss: 0.214109\tvalid_1's multi_error: 0.192497\tvalid_1's multi_logloss: 0.631202\n",
      "[54]\ttraining's multi_error: 0.0318291\ttraining's multi_logloss: 0.208036\tvalid_1's multi_error: 0.192497\tvalid_1's multi_logloss: 0.628324\n",
      "[55]\ttraining's multi_error: 0.03063\ttraining's multi_logloss: 0.202585\tvalid_1's multi_error: 0.193112\tvalid_1's multi_logloss: 0.626241\n",
      "[56]\ttraining's multi_error: 0.02845\ttraining's multi_logloss: 0.196962\tvalid_1's multi_error: 0.192497\tvalid_1's multi_logloss: 0.623584\n",
      "[57]\ttraining's multi_error: 0.0277959\ttraining's multi_logloss: 0.191728\tvalid_1's multi_error: 0.190652\tvalid_1's multi_logloss: 0.62201\n",
      "[58]\ttraining's multi_error: 0.0263789\ttraining's multi_logloss: 0.186633\tvalid_1's multi_error: 0.190037\tvalid_1's multi_logloss: 0.619491\n",
      "[59]\ttraining's multi_error: 0.0249618\ttraining's multi_logloss: 0.181903\tvalid_1's multi_error: 0.190037\tvalid_1's multi_logloss: 0.618313\n",
      "[60]\ttraining's multi_error: 0.0240898\ttraining's multi_logloss: 0.176954\tvalid_1's multi_error: 0.192497\tvalid_1's multi_logloss: 0.617215\n",
      "[61]\ttraining's multi_error: 0.0224548\ttraining's multi_logloss: 0.172416\tvalid_1's multi_error: 0.191882\tvalid_1's multi_logloss: 0.615135\n",
      "[62]\ttraining's multi_error: 0.0213647\ttraining's multi_logloss: 0.167843\tvalid_1's multi_error: 0.191267\tvalid_1's multi_logloss: 0.614126\n",
      "[63]\ttraining's multi_error: 0.0202747\ttraining's multi_logloss: 0.163534\tvalid_1's multi_error: 0.189422\tvalid_1's multi_logloss: 0.612894\n",
      "[64]\ttraining's multi_error: 0.0192937\ttraining's multi_logloss: 0.159293\tvalid_1's multi_error: 0.189422\tvalid_1's multi_logloss: 0.611872\n",
      "[65]\ttraining's multi_error: 0.0177676\ttraining's multi_logloss: 0.15522\tvalid_1's multi_error: 0.190652\tvalid_1's multi_logloss: 0.61057\n",
      "[66]\ttraining's multi_error: 0.0160235\ttraining's multi_logloss: 0.151031\tvalid_1's multi_error: 0.188807\tvalid_1's multi_logloss: 0.609692\n",
      "[67]\ttraining's multi_error: 0.0152605\ttraining's multi_logloss: 0.147338\tvalid_1's multi_error: 0.188192\tvalid_1's multi_logloss: 0.608765\n",
      "[68]\ttraining's multi_error: 0.0144975\ttraining's multi_logloss: 0.143413\tvalid_1's multi_error: 0.187577\tvalid_1's multi_logloss: 0.608222\n",
      "[69]\ttraining's multi_error: 0.0132985\ttraining's multi_logloss: 0.139648\tvalid_1's multi_error: 0.188192\tvalid_1's multi_logloss: 0.607259\n",
      "[70]\ttraining's multi_error: 0.0118814\ttraining's multi_logloss: 0.136075\tvalid_1's multi_error: 0.186962\tvalid_1's multi_logloss: 0.605771\n",
      "[71]\ttraining's multi_error: 0.0113364\ttraining's multi_logloss: 0.132596\tvalid_1's multi_error: 0.187577\tvalid_1's multi_logloss: 0.604635\n",
      "[72]\ttraining's multi_error: 0.0106824\ttraining's multi_logloss: 0.129488\tvalid_1's multi_error: 0.186962\tvalid_1's multi_logloss: 0.604161\n",
      "[73]\ttraining's multi_error: 0.00970133\ttraining's multi_logloss: 0.126396\tvalid_1's multi_error: 0.186347\tvalid_1's multi_logloss: 0.603573\n",
      "[74]\ttraining's multi_error: 0.0088293\ttraining's multi_logloss: 0.123342\tvalid_1's multi_error: 0.186347\tvalid_1's multi_logloss: 0.60309\n",
      "[75]\ttraining's multi_error: 0.00850229\ttraining's multi_logloss: 0.120375\tvalid_1's multi_error: 0.185732\tvalid_1's multi_logloss: 0.603228\n",
      "[76]\ttraining's multi_error: 0.00763026\ttraining's multi_logloss: 0.117311\tvalid_1's multi_error: 0.185117\tvalid_1's multi_logloss: 0.602126\n",
      "[77]\ttraining's multi_error: 0.00719424\ttraining's multi_logloss: 0.114469\tvalid_1's multi_error: 0.185732\tvalid_1's multi_logloss: 0.602219\n",
      "[78]\ttraining's multi_error: 0.00632221\ttraining's multi_logloss: 0.111622\tvalid_1's multi_error: 0.187577\tvalid_1's multi_logloss: 0.601717\n",
      "[79]\ttraining's multi_error: 0.00621321\ttraining's multi_logloss: 0.109103\tvalid_1's multi_error: 0.186962\tvalid_1's multi_logloss: 0.601481\n",
      "[80]\ttraining's multi_error: 0.0057772\ttraining's multi_logloss: 0.106425\tvalid_1's multi_error: 0.186347\tvalid_1's multi_logloss: 0.600355\n",
      "[81]\ttraining's multi_error: 0.00523218\ttraining's multi_logloss: 0.103849\tvalid_1's multi_error: 0.188192\tvalid_1's multi_logloss: 0.600064\n",
      "[82]\ttraining's multi_error: 0.00457816\ttraining's multi_logloss: 0.101386\tvalid_1's multi_error: 0.188807\tvalid_1's multi_logloss: 0.599644\n",
      "[83]\ttraining's multi_error: 0.00392413\ttraining's multi_logloss: 0.098949\tvalid_1's multi_error: 0.188192\tvalid_1's multi_logloss: 0.599322\n",
      "[84]\ttraining's multi_error: 0.00359712\ttraining's multi_logloss: 0.0966879\tvalid_1's multi_error: 0.188807\tvalid_1's multi_logloss: 0.599486\n",
      "[85]\ttraining's multi_error: 0.00348812\ttraining's multi_logloss: 0.0942924\tvalid_1's multi_error: 0.189422\tvalid_1's multi_logloss: 0.599207\n",
      "[86]\ttraining's multi_error: 0.00348812\ttraining's multi_logloss: 0.0920805\tvalid_1's multi_error: 0.188807\tvalid_1's multi_logloss: 0.599094\n",
      "[87]\ttraining's multi_error: 0.00316111\ttraining's multi_logloss: 0.0898689\tvalid_1's multi_error: 0.188807\tvalid_1's multi_logloss: 0.598947\n",
      "[88]\ttraining's multi_error: 0.00316111\ttraining's multi_logloss: 0.0879142\tvalid_1's multi_error: 0.187577\tvalid_1's multi_logloss: 0.598726\n",
      "[89]\ttraining's multi_error: 0.0028341\ttraining's multi_logloss: 0.0857501\tvalid_1's multi_error: 0.187577\tvalid_1's multi_logloss: 0.597904\n",
      "[90]\ttraining's multi_error: 0.00250709\ttraining's multi_logloss: 0.0837602\tvalid_1's multi_error: 0.186347\tvalid_1's multi_logloss: 0.597312\n",
      "[91]\ttraining's multi_error: 0.00218007\ttraining's multi_logloss: 0.0817477\tvalid_1's multi_error: 0.187577\tvalid_1's multi_logloss: 0.597708\n",
      "[92]\ttraining's multi_error: 0.00207107\ttraining's multi_logloss: 0.0800158\tvalid_1's multi_error: 0.187577\tvalid_1's multi_logloss: 0.597692\n",
      "[93]\ttraining's multi_error: 0.00174406\ttraining's multi_logloss: 0.07821\tvalid_1's multi_error: 0.190652\tvalid_1's multi_logloss: 0.597617\n",
      "[94]\ttraining's multi_error: 0.00163506\ttraining's multi_logloss: 0.0763446\tvalid_1's multi_error: 0.190037\tvalid_1's multi_logloss: 0.597584\n",
      "[95]\ttraining's multi_error: 0.00130804\ttraining's multi_logloss: 0.0745383\tvalid_1's multi_error: 0.190037\tvalid_1's multi_logloss: 0.597556\n",
      "[96]\ttraining's multi_error: 0.00119904\ttraining's multi_logloss: 0.0727615\tvalid_1's multi_error: 0.189422\tvalid_1's multi_logloss: 0.597826\n",
      "Early stopping, best iteration is:\n",
      "[76]\ttraining's multi_error: 0.00763026\ttraining's multi_logloss: 0.117311\tvalid_1's multi_error: 0.185117\tvalid_1's multi_logloss: 0.602126\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=LGBMClassifier(), n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': [0.01, 0.015, 0.025,\n",
       "                                                          0.05, 0.1],\n",
       "                                        'max_depth': [3, 5, 7, 9, 12, 15, 17,\n",
       "                                                      25],\n",
       "                                        'min_child_weight': [1, 3, 5, 7],\n",
       "                                        'subsample': array([0.6, 0.7, 0.8, 0.9, 1. ])},\n",
       "                   return_train_score=True, scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_clf = lgbm.LGBMClassifier()\n",
    "\n",
    "lgbm_param_grid = {'learning_rate': [.01, .015, .025, .05, .1],\n",
    "#                   'Gamma': [.05, .1, .3, .5, .7, .9, 1],\n",
    "                  'max_depth': [3, 5, 7, 9, 12, 15, 17, 25],\n",
    "                  'min_child_weight': [1, 3, 5, 7],\n",
    "                  'subsample': np.linspace(0.6, 1, 5)}\n",
    "\n",
    "fit_params = {\"early_stopping_rounds\" : 20,\n",
    "             \"eval_metric\" : \"multi_error\",\n",
    "             \"eval_set\" : [(X_train, y_train), (X_val, y_val)]}\n",
    "\n",
    "# Create a random search object\n",
    "lgbm_random = RandomizedSearchCV(estimator = lgbm_clf,\n",
    "                                param_distributions = lgbm_param_grid,\n",
    "                                n_iter = 20, # n_iters in param combinations\n",
    "                                scoring='accuracy',\n",
    "                                n_jobs=-1,\n",
    "                                cv = 5,\n",
    "                                refit=True,\n",
    "                                return_train_score = True,\n",
    "                                verbose=10)\n",
    "\n",
    "# Fit to the training data\n",
    "lgbm_random.fit(X_train, y_train, **fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = lgbm_random.best_estimator_.predict(X_train)\n",
    "pred_val = lgbm_random.best_estimator_.predict(X_val)\n",
    "pred_test = lgbm_random.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9923697405711794\n",
      "0.8148831488314883\n",
      "0.16483516483516483\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_train, pred_train))\n",
    "print(accuracy_score(y_val, pred_val))\n",
    "print(accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(max_depth=9, min_child_weight=3, subsample=0.6)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subsample</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.690103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.738936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.758339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.763244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.766405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.770111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.770220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.771419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.772292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.772401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.773600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.779159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.784500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.787880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.790059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.790060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.790060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.798017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.802594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.807500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subsample  min_child_weight  max_depth  learning_rate  mean_test_score\n",
       "0        1.0                 7          3          0.010         0.690103\n",
       "0        0.9                 7          3          0.025         0.738936\n",
       "0        0.6                 7          5          0.015         0.758339\n",
       "0        0.6                 7          7          0.010         0.763244\n",
       "0        1.0                 5          9          0.010         0.766405\n",
       "0        1.0                 7         25          0.010         0.770111\n",
       "0        0.7                 7         12          0.010         0.770220\n",
       "0        0.6                 1         12          0.010         0.771419\n",
       "0        0.6                 1          9          0.010         0.772292\n",
       "0        1.0                 3         25          0.010         0.772401\n",
       "0        1.0                 3          5          0.025         0.773600\n",
       "0        0.8                 5         17          0.015         0.779159\n",
       "0        1.0                 7         15          0.025         0.784500\n",
       "0        0.7                 3          9          0.025         0.787880\n",
       "0        1.0                 5          7          0.025         0.790059\n",
       "0        0.8                 7         17          0.025         0.790060\n",
       "0        0.8                 7         25          0.025         0.790060\n",
       "0        0.6                 3          7          0.050         0.798017\n",
       "0        0.9                 7         17          0.050         0.802594\n",
       "0        0.6                 3          9          0.100         0.807500"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_df = pd.DataFrame(lgbm_random.cv_results_)\n",
    "\n",
    "df_list = []\n",
    "for i in range(20):\n",
    "    df_list.append(pd.DataFrame([cv_result_df.loc[i, \"params\"]]))\n",
    "    \n",
    "param_table = pd.concat(df_list)\n",
    "\n",
    "param_table['mean_test_score'] = cv_result_df['mean_test_score'].values\n",
    "\n",
    "param_table.sort_values(by='mean_test_score', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
