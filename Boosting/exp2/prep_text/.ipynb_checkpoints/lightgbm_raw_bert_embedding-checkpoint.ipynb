{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "np.random.seed(4444)\n",
    "with open ('../../../../../jaeyeun/01_nh_poc/23_BERT_NH_NO_2/nh_output_20200812_raw_text_embedding/test_set_prediction.pickle', 'rb') as f:\n",
    "    emb = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_feature = []\n",
    "X_val_feature = []\n",
    "X_test_feature = []\n",
    "y_train = []\n",
    "y_val = []\n",
    "y_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for title in emb.keys():\n",
    "    data = emb[title]\n",
    "    dataset_n = data['dataset_n']\n",
    "    tvt = data['train_val_test']\n",
    "    \n",
    "    if dataset_n == '0':\n",
    "        if tvt == '0' or tvt == '1':\n",
    "            X_train_feature.append(data['feature'])\n",
    "            y_train.append(data['label'])\n",
    "        else:\n",
    "            X_val_feature.append(data['feature'])\n",
    "            y_val.append(data['label'])\n",
    "    else:\n",
    "        X_test_feature.append(data['feature'])\n",
    "        y_test.append(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train_feature)\n",
    "X_val = np.array(X_val_feature)\n",
    "X_test = np.array(X_test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9174, 768)\n",
      "(1626, 768)\n",
      "(273, 768)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9174\n",
      "1626\n",
      "273\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train))\n",
    "print(len(y_val))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* XGBoost RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import lightgbm as lgbm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of 100 | elapsed:  6.8min remaining:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done  59 out of 100 | elapsed:  7.5min remaining:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of 100 | elapsed: 10.1min remaining:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of 100 | elapsed: 11.1min remaining:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  92 out of 100 | elapsed: 11.5min remaining:   59.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 11.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's multi_error: 0.684979\ttraining's multi_logloss: 2.09772\tvalid_1's multi_error: 0.704182\tvalid_1's multi_logloss: 2.12312\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttraining's multi_error: 0.53499\ttraining's multi_logloss: 1.9702\tvalid_1's multi_error: 0.594096\tvalid_1's multi_logloss: 2.01905\n",
      "[3]\ttraining's multi_error: 0.431328\ttraining's multi_logloss: 1.8598\tvalid_1's multi_error: 0.50738\tvalid_1's multi_logloss: 1.92812\n",
      "[4]\ttraining's multi_error: 0.370722\ttraining's multi_logloss: 1.76411\tvalid_1's multi_error: 0.464945\tvalid_1's multi_logloss: 1.85543\n",
      "[5]\ttraining's multi_error: 0.334096\ttraining's multi_logloss: 1.68282\tvalid_1's multi_error: 0.437884\tvalid_1's multi_logloss: 1.79211\n",
      "[6]\ttraining's multi_error: 0.305755\ttraining's multi_logloss: 1.60628\tvalid_1's multi_error: 0.418204\tvalid_1's multi_logloss: 1.73226\n",
      "[7]\ttraining's multi_error: 0.283628\ttraining's multi_logloss: 1.53784\tvalid_1's multi_error: 0.402829\tvalid_1's multi_logloss: 1.68089\n",
      "[8]\ttraining's multi_error: 0.26477\ttraining's multi_logloss: 1.47351\tvalid_1's multi_error: 0.392989\tvalid_1's multi_logloss: 1.63504\n",
      "[9]\ttraining's multi_error: 0.252017\ttraining's multi_logloss: 1.41609\tvalid_1's multi_error: 0.373309\tvalid_1's multi_logloss: 1.59066\n",
      "[10]\ttraining's multi_error: 0.236538\ttraining's multi_logloss: 1.36291\tvalid_1's multi_error: 0.364699\tvalid_1's multi_logloss: 1.54901\n",
      "[11]\ttraining's multi_error: 0.225311\ttraining's multi_logloss: 1.31279\tvalid_1's multi_error: 0.357319\tvalid_1's multi_logloss: 1.51056\n",
      "[12]\ttraining's multi_error: 0.212993\ttraining's multi_logloss: 1.26444\tvalid_1's multi_error: 0.354859\tvalid_1's multi_logloss: 1.47389\n",
      "[13]\ttraining's multi_error: 0.205254\ttraining's multi_logloss: 1.22077\tvalid_1's multi_error: 0.348708\tvalid_1's multi_logloss: 1.4424\n",
      "[14]\ttraining's multi_error: 0.196861\ttraining's multi_logloss: 1.18083\tvalid_1's multi_error: 0.342558\tvalid_1's multi_logloss: 1.41355\n",
      "[15]\ttraining's multi_error: 0.190102\ttraining's multi_logloss: 1.14144\tvalid_1's multi_error: 0.336408\tvalid_1's multi_logloss: 1.38364\n",
      "[16]\ttraining's multi_error: 0.183453\ttraining's multi_logloss: 1.10373\tvalid_1's multi_error: 0.338868\tvalid_1's multi_logloss: 1.35702\n",
      "[17]\ttraining's multi_error: 0.176695\ttraining's multi_logloss: 1.06974\tvalid_1's multi_error: 0.334563\tvalid_1's multi_logloss: 1.33167\n",
      "[18]\ttraining's multi_error: 0.172008\ttraining's multi_logloss: 1.03727\tvalid_1's multi_error: 0.327798\tvalid_1's multi_logloss: 1.30799\n",
      "[19]\ttraining's multi_error: 0.16525\ttraining's multi_logloss: 1.00629\tvalid_1's multi_error: 0.316728\tvalid_1's multi_logloss: 1.286\n",
      "[20]\ttraining's multi_error: 0.160671\ttraining's multi_logloss: 0.977169\tvalid_1's multi_error: 0.309963\tvalid_1's multi_logloss: 1.26441\n",
      "[21]\ttraining's multi_error: 0.156311\ttraining's multi_logloss: 0.95\tvalid_1's multi_error: 0.311808\tvalid_1's multi_logloss: 1.24435\n",
      "[22]\ttraining's multi_error: 0.151079\ttraining's multi_logloss: 0.923541\tvalid_1's multi_error: 0.314268\tvalid_1's multi_logloss: 1.22741\n",
      "[23]\ttraining's multi_error: 0.147482\ttraining's multi_logloss: 0.89754\tvalid_1's multi_error: 0.312423\tvalid_1's multi_logloss: 1.20877\n",
      "[24]\ttraining's multi_error: 0.142468\ttraining's multi_logloss: 0.873844\tvalid_1's multi_error: 0.310578\tvalid_1's multi_logloss: 1.19237\n",
      "[25]\ttraining's multi_error: 0.138762\ttraining's multi_logloss: 0.850734\tvalid_1's multi_error: 0.309963\tvalid_1's multi_logloss: 1.17626\n",
      "[26]\ttraining's multi_error: 0.134402\ttraining's multi_logloss: 0.827763\tvalid_1's multi_error: 0.311193\tvalid_1's multi_logloss: 1.16097\n",
      "[27]\ttraining's multi_error: 0.129278\ttraining's multi_logloss: 0.806681\tvalid_1's multi_error: 0.306273\tvalid_1's multi_logloss: 1.1468\n",
      "[28]\ttraining's multi_error: 0.124809\ttraining's multi_logloss: 0.786531\tvalid_1's multi_error: 0.306888\tvalid_1's multi_logloss: 1.13401\n",
      "[29]\ttraining's multi_error: 0.120994\ttraining's multi_logloss: 0.766327\tvalid_1's multi_error: 0.306888\tvalid_1's multi_logloss: 1.12126\n",
      "[30]\ttraining's multi_error: 0.115871\ttraining's multi_logloss: 0.747771\tvalid_1's multi_error: 0.304428\tvalid_1's multi_logloss: 1.10808\n",
      "[31]\ttraining's multi_error: 0.112819\ttraining's multi_logloss: 0.72983\tvalid_1's multi_error: 0.300123\tvalid_1's multi_logloss: 1.09683\n",
      "[32]\ttraining's multi_error: 0.109222\ttraining's multi_logloss: 0.712734\tvalid_1's multi_error: 0.300123\tvalid_1's multi_logloss: 1.08503\n",
      "[33]\ttraining's multi_error: 0.106933\ttraining's multi_logloss: 0.694902\tvalid_1's multi_error: 0.298278\tvalid_1's multi_logloss: 1.07305\n",
      "[34]\ttraining's multi_error: 0.103772\ttraining's multi_logloss: 0.679092\tvalid_1's multi_error: 0.295203\tvalid_1's multi_logloss: 1.06215\n",
      "[35]\ttraining's multi_error: 0.102245\ttraining's multi_logloss: 0.663588\tvalid_1's multi_error: 0.292743\tvalid_1's multi_logloss: 1.05249\n",
      "[36]\ttraining's multi_error: 0.0990844\ttraining's multi_logloss: 0.648558\tvalid_1's multi_error: 0.292128\tvalid_1's multi_logloss: 1.04307\n",
      "[37]\ttraining's multi_error: 0.0972313\ttraining's multi_logloss: 0.634675\tvalid_1's multi_error: 0.292128\tvalid_1's multi_logloss: 1.03396\n",
      "[38]\ttraining's multi_error: 0.0940702\ttraining's multi_logloss: 0.620869\tvalid_1's multi_error: 0.292743\tvalid_1's multi_logloss: 1.02569\n",
      "[39]\ttraining's multi_error: 0.0917811\ttraining's multi_logloss: 0.607483\tvalid_1's multi_error: 0.292128\tvalid_1's multi_logloss: 1.0164\n",
      "[40]\ttraining's multi_error: 0.089056\ttraining's multi_logloss: 0.595504\tvalid_1's multi_error: 0.292128\tvalid_1's multi_logloss: 1.00835\n",
      "[41]\ttraining's multi_error: 0.0863309\ttraining's multi_logloss: 0.582576\tvalid_1's multi_error: 0.287823\tvalid_1's multi_logloss: 1.00002\n",
      "[42]\ttraining's multi_error: 0.0844779\ttraining's multi_logloss: 0.570067\tvalid_1's multi_error: 0.285978\tvalid_1's multi_logloss: 0.992683\n",
      "[43]\ttraining's multi_error: 0.0824068\ttraining's multi_logloss: 0.558558\tvalid_1's multi_error: 0.284748\tvalid_1's multi_logloss: 0.984955\n",
      "[44]\ttraining's multi_error: 0.0796817\ttraining's multi_logloss: 0.546764\tvalid_1's multi_error: 0.285363\tvalid_1's multi_logloss: 0.977838\n",
      "[45]\ttraining's multi_error: 0.0767386\ttraining's multi_logloss: 0.535169\tvalid_1's multi_error: 0.285363\tvalid_1's multi_logloss: 0.97147\n",
      "[46]\ttraining's multi_error: 0.0747765\ttraining's multi_logloss: 0.524503\tvalid_1's multi_error: 0.282903\tvalid_1's multi_logloss: 0.965273\n",
      "[47]\ttraining's multi_error: 0.0728145\ttraining's multi_logloss: 0.513703\tvalid_1's multi_error: 0.281673\tvalid_1's multi_logloss: 0.958156\n",
      "[48]\ttraining's multi_error: 0.0707434\ttraining's multi_logloss: 0.504832\tvalid_1's multi_error: 0.281058\tvalid_1's multi_logloss: 0.951929\n",
      "[49]\ttraining's multi_error: 0.0692174\ttraining's multi_logloss: 0.495323\tvalid_1's multi_error: 0.276753\tvalid_1's multi_logloss: 0.94575\n",
      "[50]\ttraining's multi_error: 0.0674733\ttraining's multi_logloss: 0.4866\tvalid_1's multi_error: 0.279213\tvalid_1's multi_logloss: 0.940104\n",
      "[51]\ttraining's multi_error: 0.0656202\ttraining's multi_logloss: 0.47771\tvalid_1's multi_error: 0.276138\tvalid_1's multi_logloss: 0.934811\n",
      "[52]\ttraining's multi_error: 0.0640942\ttraining's multi_logloss: 0.469789\tvalid_1's multi_error: 0.273678\tvalid_1's multi_logloss: 0.930339\n",
      "[53]\ttraining's multi_error: 0.0623501\ttraining's multi_logloss: 0.460089\tvalid_1's multi_error: 0.273678\tvalid_1's multi_logloss: 0.92556\n",
      "[54]\ttraining's multi_error: 0.0608241\ttraining's multi_logloss: 0.452188\tvalid_1's multi_error: 0.271833\tvalid_1's multi_logloss: 0.921392\n",
      "[55]\ttraining's multi_error: 0.059734\ttraining's multi_logloss: 0.443846\tvalid_1's multi_error: 0.272448\tvalid_1's multi_logloss: 0.917263\n",
      "[56]\ttraining's multi_error: 0.058862\ttraining's multi_logloss: 0.435821\tvalid_1's multi_error: 0.269373\tvalid_1's multi_logloss: 0.912427\n",
      "[57]\ttraining's multi_error: 0.0561369\ttraining's multi_logloss: 0.427825\tvalid_1's multi_error: 0.268143\tvalid_1's multi_logloss: 0.90821\n",
      "[58]\ttraining's multi_error: 0.0558099\ttraining's multi_logloss: 0.42013\tvalid_1's multi_error: 0.265068\tvalid_1's multi_logloss: 0.903753\n",
      "[59]\ttraining's multi_error: 0.0539568\ttraining's multi_logloss: 0.41319\tvalid_1's multi_error: 0.265068\tvalid_1's multi_logloss: 0.899883\n",
      "[60]\ttraining's multi_error: 0.0527578\ttraining's multi_logloss: 0.405926\tvalid_1's multi_error: 0.265068\tvalid_1's multi_logloss: 0.895685\n",
      "[61]\ttraining's multi_error: 0.0509047\ttraining's multi_logloss: 0.39925\tvalid_1's multi_error: 0.264453\tvalid_1's multi_logloss: 0.892474\n",
      "[62]\ttraining's multi_error: 0.0488337\ttraining's multi_logloss: 0.392361\tvalid_1's multi_error: 0.263223\tvalid_1's multi_logloss: 0.888817\n",
      "[63]\ttraining's multi_error: 0.0468716\ttraining's multi_logloss: 0.385721\tvalid_1's multi_error: 0.261378\tvalid_1's multi_logloss: 0.884658\n",
      "[64]\ttraining's multi_error: 0.0449095\ttraining's multi_logloss: 0.379574\tvalid_1's multi_error: 0.263838\tvalid_1's multi_logloss: 0.881177\n",
      "[65]\ttraining's multi_error: 0.0432745\ttraining's multi_logloss: 0.372507\tvalid_1's multi_error: 0.264453\tvalid_1's multi_logloss: 0.877496\n",
      "[66]\ttraining's multi_error: 0.0413124\ttraining's multi_logloss: 0.36631\tvalid_1's multi_error: 0.262608\tvalid_1's multi_logloss: 0.874417\n",
      "[67]\ttraining's multi_error: 0.0395683\ttraining's multi_logloss: 0.35977\tvalid_1's multi_error: 0.261993\tvalid_1's multi_logloss: 0.871433\n",
      "[68]\ttraining's multi_error: 0.0382603\ttraining's multi_logloss: 0.354547\tvalid_1's multi_error: 0.260148\tvalid_1's multi_logloss: 0.868416\n",
      "[69]\ttraining's multi_error: 0.0372793\ttraining's multi_logloss: 0.34874\tvalid_1's multi_error: 0.260148\tvalid_1's multi_logloss: 0.866697\n",
      "[70]\ttraining's multi_error: 0.0361892\ttraining's multi_logloss: 0.343227\tvalid_1's multi_error: 0.261993\tvalid_1's multi_logloss: 0.864887\n",
      "[71]\ttraining's multi_error: 0.0350992\ttraining's multi_logloss: 0.338087\tvalid_1's multi_error: 0.262608\tvalid_1's multi_logloss: 0.862238\n",
      "[72]\ttraining's multi_error: 0.0343362\ttraining's multi_logloss: 0.332536\tvalid_1's multi_error: 0.261378\tvalid_1's multi_logloss: 0.859679\n",
      "[73]\ttraining's multi_error: 0.0330281\ttraining's multi_logloss: 0.327468\tvalid_1's multi_error: 0.261993\tvalid_1's multi_logloss: 0.85774\n",
      "[74]\ttraining's multi_error: 0.0322651\ttraining's multi_logloss: 0.322398\tvalid_1's multi_error: 0.260763\tvalid_1's multi_logloss: 0.854986\n",
      "[75]\ttraining's multi_error: 0.0312841\ttraining's multi_logloss: 0.317086\tvalid_1's multi_error: 0.261378\tvalid_1's multi_logloss: 0.852548\n",
      "[76]\ttraining's multi_error: 0.03063\ttraining's multi_logloss: 0.312633\tvalid_1's multi_error: 0.261378\tvalid_1's multi_logloss: 0.85035\n",
      "[77]\ttraining's multi_error: 0.029758\ttraining's multi_logloss: 0.308289\tvalid_1's multi_error: 0.263223\tvalid_1's multi_logloss: 0.84813\n",
      "[78]\ttraining's multi_error: 0.028559\ttraining's multi_logloss: 0.303341\tvalid_1's multi_error: 0.261993\tvalid_1's multi_logloss: 0.845912\n",
      "[79]\ttraining's multi_error: 0.028232\ttraining's multi_logloss: 0.299403\tvalid_1's multi_error: 0.259533\tvalid_1's multi_logloss: 0.84436\n",
      "[80]\ttraining's multi_error: 0.0270329\ttraining's multi_logloss: 0.295044\tvalid_1's multi_error: 0.258918\tvalid_1's multi_logloss: 0.8427\n",
      "[81]\ttraining's multi_error: 0.0262699\ttraining's multi_logloss: 0.290275\tvalid_1's multi_error: 0.257688\tvalid_1's multi_logloss: 0.840958\n",
      "[82]\ttraining's multi_error: 0.0251799\ttraining's multi_logloss: 0.285603\tvalid_1's multi_error: 0.255228\tvalid_1's multi_logloss: 0.83822\n",
      "[83]\ttraining's multi_error: 0.0241988\ttraining's multi_logloss: 0.281893\tvalid_1's multi_error: 0.255843\tvalid_1's multi_logloss: 0.836139\n",
      "[84]\ttraining's multi_error: 0.0231088\ttraining's multi_logloss: 0.277903\tvalid_1's multi_error: 0.257688\tvalid_1's multi_logloss: 0.834496\n",
      "[85]\ttraining's multi_error: 0.0225638\ttraining's multi_logloss: 0.273933\tvalid_1's multi_error: 0.257688\tvalid_1's multi_logloss: 0.832205\n",
      "[86]\ttraining's multi_error: 0.0211467\ttraining's multi_logloss: 0.270105\tvalid_1's multi_error: 0.256458\tvalid_1's multi_logloss: 0.829701\n",
      "[87]\ttraining's multi_error: 0.0212557\ttraining's multi_logloss: 0.26591\tvalid_1's multi_error: 0.254613\tvalid_1's multi_logloss: 0.827671\n",
      "[88]\ttraining's multi_error: 0.0202747\ttraining's multi_logloss: 0.262204\tvalid_1's multi_error: 0.253998\tvalid_1's multi_logloss: 0.825068\n",
      "[89]\ttraining's multi_error: 0.0197297\ttraining's multi_logloss: 0.258453\tvalid_1's multi_error: 0.253383\tvalid_1's multi_logloss: 0.823449\n",
      "[90]\ttraining's multi_error: 0.0190756\ttraining's multi_logloss: 0.254518\tvalid_1's multi_error: 0.254613\tvalid_1's multi_logloss: 0.821659\n",
      "[91]\ttraining's multi_error: 0.0178766\ttraining's multi_logloss: 0.250782\tvalid_1's multi_error: 0.252153\tvalid_1's multi_logloss: 0.819096\n",
      "[92]\ttraining's multi_error: 0.0177676\ttraining's multi_logloss: 0.247851\tvalid_1's multi_error: 0.250923\tvalid_1's multi_logloss: 0.817971\n",
      "[93]\ttraining's multi_error: 0.0171136\ttraining's multi_logloss: 0.24447\tvalid_1's multi_error: 0.247847\tvalid_1's multi_logloss: 0.815615\n",
      "[94]\ttraining's multi_error: 0.0166776\ttraining's multi_logloss: 0.241326\tvalid_1's multi_error: 0.247232\tvalid_1's multi_logloss: 0.814116\n",
      "[95]\ttraining's multi_error: 0.0160235\ttraining's multi_logloss: 0.238143\tvalid_1's multi_error: 0.247232\tvalid_1's multi_logloss: 0.812699\n",
      "[96]\ttraining's multi_error: 0.0156965\ttraining's multi_logloss: 0.23495\tvalid_1's multi_error: 0.247847\tvalid_1's multi_logloss: 0.811104\n",
      "[97]\ttraining's multi_error: 0.0153695\ttraining's multi_logloss: 0.231686\tvalid_1's multi_error: 0.247232\tvalid_1's multi_logloss: 0.809981\n",
      "[98]\ttraining's multi_error: 0.0150425\ttraining's multi_logloss: 0.228499\tvalid_1's multi_error: 0.246617\tvalid_1's multi_logloss: 0.808849\n",
      "[99]\ttraining's multi_error: 0.0143885\ttraining's multi_logloss: 0.225719\tvalid_1's multi_error: 0.246617\tvalid_1's multi_logloss: 0.807979\n",
      "[100]\ttraining's multi_error: 0.0139525\ttraining's multi_logloss: 0.222002\tvalid_1's multi_error: 0.243542\tvalid_1's multi_logloss: 0.805928\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's multi_error: 0.0139525\ttraining's multi_logloss: 0.222002\tvalid_1's multi_error: 0.243542\tvalid_1's multi_logloss: 0.805928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=LGBMClassifier(), n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': [0.01, 0.015, 0.025,\n",
       "                                                          0.05, 0.1],\n",
       "                                        'max_depth': [3, 5, 7, 9, 12, 15, 17,\n",
       "                                                      25],\n",
       "                                        'min_child_weight': [1, 3, 5, 7],\n",
       "                                        'subsample': array([0.6, 0.7, 0.8, 0.9, 1. ])},\n",
       "                   return_train_score=True, scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_clf = lgbm.LGBMClassifier()\n",
    "\n",
    "lgbm_param_grid = {'learning_rate': [.01, .015, .025, .05, .1],\n",
    "#                   'Gamma': [.05, .1, .3, .5, .7, .9, 1],\n",
    "                  'max_depth': [3, 5, 7, 9, 12, 15, 17, 25],\n",
    "                  'min_child_weight': [1, 3, 5, 7],\n",
    "                  'subsample': np.linspace(0.6, 1, 5)}\n",
    "\n",
    "fit_params = {\"early_stopping_rounds\" : 20,\n",
    "             \"eval_metric\" : \"multi_error\",\n",
    "             \"eval_set\" : [(X_train, y_train), (X_val, y_val)]}\n",
    "\n",
    "# Create a random search object\n",
    "lgbm_random = RandomizedSearchCV(estimator = lgbm_clf,\n",
    "                                param_distributions = lgbm_param_grid,\n",
    "                                n_iter = 20, # n_iters in param combinations\n",
    "                                scoring='accuracy',\n",
    "                                n_jobs=-1,\n",
    "                                cv = 5,\n",
    "                                refit=True,\n",
    "                                return_train_score = True,\n",
    "                                verbose=10)\n",
    "\n",
    "# Fit to the training data\n",
    "lgbm_random.fit(X_train, y_train, **fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = lgbm_random.best_estimator_.predict(X_train)\n",
    "pred_val = lgbm_random.best_estimator_.predict(X_val)\n",
    "pred_test = lgbm_random.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.986047525615871\n",
      "0.7564575645756457\n",
      "0.3553113553113553\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_train, pred_train))\n",
    "print(accuracy_score(y_val, pred_val))\n",
    "print(accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(max_depth=5, min_child_weight=3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_cv_result_df = pd.DataFrame(lgbm_random.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for i in range(20):\n",
    "    df_list.append(pd.DataFrame([lgbm_cv_result_df.loc[i, \"params\"]]))\n",
    "    \n",
    "lgbm_param_table = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_param_table['mean_test_score'] = lgbm_cv_result_df['mean_test_score'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subsample</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.629278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.632004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.633530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.641378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.642577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.654567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.659800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.659800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.664487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.706997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.720187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.721495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.721496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.725638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.728908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.735993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.736973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.736973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.736973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.737192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subsample  min_child_weight  max_depth  learning_rate  mean_test_score\n",
       "0        0.8                 1         25          0.010         0.629278\n",
       "0        0.7                 5          7          0.010         0.632004\n",
       "0        0.6                 7         15          0.010         0.633530\n",
       "0        0.8                 1          5          0.015         0.641378\n",
       "0        1.0                 3          5          0.015         0.642577\n",
       "0        0.8                 3          3          0.050         0.654567\n",
       "0        0.9                 3         25          0.015         0.659800\n",
       "0        0.8                 3         15          0.015         0.659800\n",
       "0        1.0                 7          9          0.015         0.664487\n",
       "0        0.8                 3          3          0.100         0.706997\n",
       "0        1.0                 1         25          0.050         0.720187\n",
       "0        1.0                 1         15          0.050         0.721495\n",
       "0        1.0                 3         25          0.050         0.721496\n",
       "0        0.7                 5         15          0.050         0.725638\n",
       "0        0.9                 7         25          0.050         0.728908\n",
       "0        0.8                 5          5          0.100         0.735993\n",
       "0        0.6                 7          5          0.100         0.736973\n",
       "0        1.0                 7          5          0.100         0.736973\n",
       "0        0.9                 7          5          0.100         0.736973\n",
       "0        1.0                 3          5          0.100         0.737192"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_param_table.sort_values(by='mean_test_score', axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
