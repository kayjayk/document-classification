{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(4444)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>dataset_n</th>\n",
       "      <th>train_val_test</th>\n",
       "      <th>prep_v9_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R1509261.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>보 도 자 료\\nhttp://www.msip.go.kr 보도일시 2015. 9. 4...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>온라인N 제도N 혁신N 관호N 미래N 사이트N 플러그인N 지원N 대응N 현황N 공개...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R2003733.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>보도일시 2020. 3. 18.(수) 조간(온라인 3. 17. 12:00)부터 보도...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>온라인N 정보N 산업N 기반N 유승N ictS 분야N 창업N 벤처N 지원N 사업N ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D1507076-1.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>보 도 자 료\\nhttp://www.msip.go.kr 보도일시 2015. 7. 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>이후N 연구N 예산N 내년도N 연구N 개발N r&amp;dN 경제N 혁신N 미래N 성장N ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R2005031.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>보 도 자 료\\n배포일시 2020. 4. 29.(수) 총 4매(본문2) 담당 부서 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>첨단N 항공N 과장N 문석N 홍일산N 이후N 가능N 일상N 시대N 개막N 시행N 전...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R2006226.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;전매체&gt; 2020년 6월 3일(수) 10:00(국무회의 개최시)부터 보도하여 주시...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>국무회의N 개최N 문의N 기획N 재정관N 과장N 서기관N 위기N 혁신N 기회N 벤처...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file_name  label                                           raw_text  \\\n",
       "0    R1509261.txt      0  보 도 자 료\\nhttp://www.msip.go.kr 보도일시 2015. 9. 4...   \n",
       "1    R2003733.txt      0  보도일시 2020. 3. 18.(수) 조간(온라인 3. 17. 12:00)부터 보도...   \n",
       "2  D1507076-1.txt      0  보 도 자 료\\nhttp://www.msip.go.kr 보도일시 2015. 7. 1...   \n",
       "3    R2005031.txt      0  보 도 자 료\\n배포일시 2020. 4. 29.(수) 총 4매(본문2) 담당 부서 ...   \n",
       "4    R2006226.txt      0  <전매체> 2020년 6월 3일(수) 10:00(국무회의 개최시)부터 보도하여 주시...   \n",
       "\n",
       "   dataset_n  train_val_test  \\\n",
       "0          0               0   \n",
       "1          0               0   \n",
       "2          0               0   \n",
       "3          0               0   \n",
       "4          0               0   \n",
       "\n",
       "                                        prep_v9_text  \n",
       "0  온라인N 제도N 혁신N 관호N 미래N 사이트N 플러그인N 지원N 대응N 현황N 공개...  \n",
       "1  온라인N 정보N 산업N 기반N 유승N ictS 분야N 창업N 벤처N 지원N 사업N ...  \n",
       "2  이후N 연구N 예산N 내년도N 연구N 개발N r&dN 경제N 혁신N 미래N 성장N ...  \n",
       "3  첨단N 항공N 과장N 문석N 홍일산N 이후N 가능N 일상N 시대N 개막N 시행N 전...  \n",
       "4  국무회의N 개최N 문의N 기획N 재정관N 과장N 서기관N 위기N 혁신N 기회N 벤처...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../../../../../jaeyeun/01_nh_poc/17_add_prep_text_to_excel/split_70_15_15_prep_v9.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* exp3 combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = df[df['train_val_test'] == 0]\n",
    "X_val_df = df[df['train_val_test'] == 1]\n",
    "X_test_df = df[df['train_val_test'] == 2]\n",
    "y_train = df[df['train_val_test'] == 0]['label']\n",
    "y_val = df[df['train_val_test'] == 1]['label']\n",
    "y_test = df[df['train_val_test'] == 2]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7740, 6)\n",
      "(1662, 6)\n",
      "(1671, 6)\n",
      "(7740,)\n",
      "(1662,)\n",
      "(1671,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_df.shape)\n",
    "print(X_val_df.shape)\n",
    "print(X_test_df.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 100000\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_df=0.9, # 0.9 만큼의 문서 이상에서 나오면 거른다.\n",
    "    min_df=5, # 5개 미만의 문서에서 나오면 거른다.\n",
    "    sublinear_tf = True, # tf value를 완만하게 처리 (outlier 처리 효과)\n",
    "    ngram_range = (1, 3),\n",
    "    max_features=n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* data is 'prep_v9_text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf_vectorizer.fit(X_train_df['prep_v9_text'])\n",
    "# X_test_tfidf = tfidf_vectorizer.fit_transform(prep_text_test)\n",
    "# X_test_hash = hash_vectorizer.fit_transform(prep_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_tfidf.transform(X_train_df['prep_v9_text'])\n",
    "X_val = X_train_tfidf.transform(X_val_df['prep_v9_text'])\n",
    "X_test = X_train_tfidf.transform(X_test_df['prep_v9_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7740, 100000)\n",
      "(1662, 100000)\n",
      "(1671, 100000)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* LightGBM RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed: 34.0min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed: 49.1min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 56.8min\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of 100 | elapsed: 86.6min remaining: 93.8min\n",
      "[Parallel(n_jobs=-1)]: Done  59 out of 100 | elapsed: 96.8min remaining: 67.2min\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of 100 | elapsed: 107.8min remaining: 46.2min\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of 100 | elapsed: 122.6min remaining: 28.8min\n",
      "[Parallel(n_jobs=-1)]: Done  92 out of 100 | elapsed: 135.6min remaining: 11.8min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 154.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's multi_error: 0.450388\ttraining's multi_logloss: 1.95442\tvalid_1's multi_error: 0.477738\tvalid_1's multi_logloss: 1.97648\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttraining's multi_error: 0.247416\ttraining's multi_logloss: 1.74089\tvalid_1's multi_error: 0.309868\tvalid_1's multi_logloss: 1.79133\n",
      "[3]\ttraining's multi_error: 0.187597\ttraining's multi_logloss: 1.57555\tvalid_1's multi_error: 0.262936\tvalid_1's multi_logloss: 1.64488\n",
      "[4]\ttraining's multi_error: 0.152455\ttraining's multi_logloss: 1.43856\tvalid_1's multi_error: 0.240072\tvalid_1's multi_logloss: 1.5269\n",
      "[5]\ttraining's multi_error: 0.139147\ttraining's multi_logloss: 1.3231\tvalid_1's multi_error: 0.229242\tvalid_1's multi_logloss: 1.42901\n",
      "[6]\ttraining's multi_error: 0.129328\ttraining's multi_logloss: 1.22368\tvalid_1's multi_error: 0.222022\tvalid_1's multi_logloss: 1.34512\n",
      "[7]\ttraining's multi_error: 0.121835\ttraining's multi_logloss: 1.13767\tvalid_1's multi_error: 0.219615\tvalid_1's multi_logloss: 1.27372\n",
      "[8]\ttraining's multi_error: 0.117054\ttraining's multi_logloss: 1.06154\tvalid_1's multi_error: 0.214801\tvalid_1's multi_logloss: 1.21162\n",
      "[9]\ttraining's multi_error: 0.112661\ttraining's multi_logloss: 0.992726\tvalid_1's multi_error: 0.209386\tvalid_1's multi_logloss: 1.15408\n",
      "[10]\ttraining's multi_error: 0.106202\ttraining's multi_logloss: 0.931126\tvalid_1's multi_error: 0.205776\tvalid_1's multi_logloss: 1.10413\n",
      "[11]\ttraining's multi_error: 0.102326\ttraining's multi_logloss: 0.875912\tvalid_1's multi_error: 0.203369\tvalid_1's multi_logloss: 1.05993\n",
      "[12]\ttraining's multi_error: 0.100129\ttraining's multi_logloss: 0.826005\tvalid_1's multi_error: 0.20698\tvalid_1's multi_logloss: 1.01887\n",
      "[13]\ttraining's multi_error: 0.0978036\ttraining's multi_logloss: 0.780906\tvalid_1's multi_error: 0.208183\tvalid_1's multi_logloss: 0.983085\n",
      "[14]\ttraining's multi_error: 0.0932817\ttraining's multi_logloss: 0.739194\tvalid_1's multi_error: 0.209988\tvalid_1's multi_logloss: 0.950344\n",
      "[15]\ttraining's multi_error: 0.0901809\ttraining's multi_logloss: 0.701097\tvalid_1's multi_error: 0.209988\tvalid_1's multi_logloss: 0.920362\n",
      "[16]\ttraining's multi_error: 0.0864341\ttraining's multi_logloss: 0.666086\tvalid_1's multi_error: 0.203971\tvalid_1's multi_logloss: 0.892682\n",
      "[17]\ttraining's multi_error: 0.0846253\ttraining's multi_logloss: 0.633913\tvalid_1's multi_error: 0.200963\tvalid_1's multi_logloss: 0.868615\n",
      "[18]\ttraining's multi_error: 0.0819121\ttraining's multi_logloss: 0.604308\tvalid_1's multi_error: 0.199759\tvalid_1's multi_logloss: 0.846438\n",
      "[19]\ttraining's multi_error: 0.079199\ttraining's multi_logloss: 0.576591\tvalid_1's multi_error: 0.199759\tvalid_1's multi_logloss: 0.825569\n",
      "[20]\ttraining's multi_error: 0.0775194\ttraining's multi_logloss: 0.550446\tvalid_1's multi_error: 0.199158\tvalid_1's multi_logloss: 0.806578\n",
      "[21]\ttraining's multi_error: 0.0749354\ttraining's multi_logloss: 0.526151\tvalid_1's multi_error: 0.198556\tvalid_1's multi_logloss: 0.789641\n",
      "[22]\ttraining's multi_error: 0.0737726\ttraining's multi_logloss: 0.503257\tvalid_1's multi_error: 0.199158\tvalid_1's multi_logloss: 0.772574\n",
      "[23]\ttraining's multi_error: 0.0719638\ttraining's multi_logloss: 0.481803\tvalid_1's multi_error: 0.198556\tvalid_1's multi_logloss: 0.757042\n",
      "[24]\ttraining's multi_error: 0.0692506\ttraining's multi_logloss: 0.461681\tvalid_1's multi_error: 0.199158\tvalid_1's multi_logloss: 0.742827\n",
      "[25]\ttraining's multi_error: 0.0680879\ttraining's multi_logloss: 0.442875\tvalid_1's multi_error: 0.194344\tvalid_1's multi_logloss: 0.730262\n",
      "[26]\ttraining's multi_error: 0.0652455\ttraining's multi_logloss: 0.424729\tvalid_1's multi_error: 0.195548\tvalid_1's multi_logloss: 0.718331\n",
      "[27]\ttraining's multi_error: 0.0617571\ttraining's multi_logloss: 0.407637\tvalid_1's multi_error: 0.197353\tvalid_1's multi_logloss: 0.707008\n",
      "[28]\ttraining's multi_error: 0.0593023\ttraining's multi_logloss: 0.39146\tvalid_1's multi_error: 0.194946\tvalid_1's multi_logloss: 0.697291\n",
      "[29]\ttraining's multi_error: 0.0578811\ttraining's multi_logloss: 0.376119\tvalid_1's multi_error: 0.191937\tvalid_1's multi_logloss: 0.688194\n",
      "[30]\ttraining's multi_error: 0.055168\ttraining's multi_logloss: 0.361443\tvalid_1's multi_error: 0.192539\tvalid_1's multi_logloss: 0.679671\n",
      "[31]\ttraining's multi_error: 0.0529716\ttraining's multi_logloss: 0.34775\tvalid_1's multi_error: 0.192539\tvalid_1's multi_logloss: 0.671501\n",
      "[32]\ttraining's multi_error: 0.0498708\ttraining's multi_logloss: 0.33463\tvalid_1's multi_error: 0.190734\tvalid_1's multi_logloss: 0.663328\n",
      "[33]\ttraining's multi_error: 0.0471576\ttraining's multi_logloss: 0.322192\tvalid_1's multi_error: 0.192539\tvalid_1's multi_logloss: 0.656497\n",
      "[34]\ttraining's multi_error: 0.0456072\ttraining's multi_logloss: 0.310398\tvalid_1's multi_error: 0.191336\tvalid_1's multi_logloss: 0.650043\n",
      "[35]\ttraining's multi_error: 0.0434109\ttraining's multi_logloss: 0.298918\tvalid_1's multi_error: 0.190734\tvalid_1's multi_logloss: 0.643482\n",
      "[36]\ttraining's multi_error: 0.0417313\ttraining's multi_logloss: 0.288256\tvalid_1's multi_error: 0.187726\tvalid_1's multi_logloss: 0.637244\n",
      "[37]\ttraining's multi_error: 0.0397933\ttraining's multi_logloss: 0.278482\tvalid_1's multi_error: 0.186522\tvalid_1's multi_logloss: 0.630821\n",
      "[38]\ttraining's multi_error: 0.0378553\ttraining's multi_logloss: 0.268616\tvalid_1's multi_error: 0.185319\tvalid_1's multi_logloss: 0.626046\n",
      "[39]\ttraining's multi_error: 0.0366925\ttraining's multi_logloss: 0.258945\tvalid_1's multi_error: 0.184116\tvalid_1's multi_logloss: 0.620806\n",
      "[40]\ttraining's multi_error: 0.0343669\ttraining's multi_logloss: 0.250095\tvalid_1's multi_error: 0.184717\tvalid_1's multi_logloss: 0.6163\n",
      "[41]\ttraining's multi_error: 0.0326873\ttraining's multi_logloss: 0.241301\tvalid_1's multi_error: 0.183514\tvalid_1's multi_logloss: 0.612013\n",
      "[42]\ttraining's multi_error: 0.030491\ttraining's multi_logloss: 0.23304\tvalid_1's multi_error: 0.183514\tvalid_1's multi_logloss: 0.606993\n",
      "[43]\ttraining's multi_error: 0.0289406\ttraining's multi_logloss: 0.225416\tvalid_1's multi_error: 0.18231\tvalid_1's multi_logloss: 0.603701\n",
      "[44]\ttraining's multi_error: 0.0273902\ttraining's multi_logloss: 0.217872\tvalid_1's multi_error: 0.180505\tvalid_1's multi_logloss: 0.600298\n",
      "[45]\ttraining's multi_error: 0.0260982\ttraining's multi_logloss: 0.210798\tvalid_1's multi_error: 0.180505\tvalid_1's multi_logloss: 0.596627\n",
      "[46]\ttraining's multi_error: 0.023385\ttraining's multi_logloss: 0.20407\tvalid_1's multi_error: 0.18231\tvalid_1's multi_logloss: 0.592346\n",
      "[47]\ttraining's multi_error: 0.0226098\ttraining's multi_logloss: 0.197468\tvalid_1's multi_error: 0.182912\tvalid_1's multi_logloss: 0.58854\n",
      "[48]\ttraining's multi_error: 0.0209302\ttraining's multi_logloss: 0.191124\tvalid_1's multi_error: 0.181709\tvalid_1's multi_logloss: 0.585726\n",
      "[49]\ttraining's multi_error: 0.0197674\ttraining's multi_logloss: 0.185013\tvalid_1's multi_error: 0.177497\tvalid_1's multi_logloss: 0.582584\n",
      "[50]\ttraining's multi_error: 0.0186047\ttraining's multi_logloss: 0.179202\tvalid_1's multi_error: 0.179302\tvalid_1's multi_logloss: 0.57992\n",
      "[51]\ttraining's multi_error: 0.0177003\ttraining's multi_logloss: 0.173643\tvalid_1's multi_error: 0.178099\tvalid_1's multi_logloss: 0.577557\n",
      "[52]\ttraining's multi_error: 0.0161499\ttraining's multi_logloss: 0.16835\tvalid_1's multi_error: 0.176895\tvalid_1's multi_logloss: 0.574892\n",
      "[53]\ttraining's multi_error: 0.0156331\ttraining's multi_logloss: 0.163061\tvalid_1's multi_error: 0.176294\tvalid_1's multi_logloss: 0.572385\n",
      "[54]\ttraining's multi_error: 0.0149871\ttraining's multi_logloss: 0.158081\tvalid_1's multi_error: 0.177497\tvalid_1's multi_logloss: 0.570526\n",
      "[55]\ttraining's multi_error: 0.0142119\ttraining's multi_logloss: 0.153183\tvalid_1's multi_error: 0.177497\tvalid_1's multi_logloss: 0.568334\n",
      "[56]\ttraining's multi_error: 0.0131783\ttraining's multi_logloss: 0.148742\tvalid_1's multi_error: 0.176294\tvalid_1's multi_logloss: 0.566539\n",
      "[57]\ttraining's multi_error: 0.0122739\ttraining's multi_logloss: 0.144372\tvalid_1's multi_error: 0.176294\tvalid_1's multi_logloss: 0.565038\n",
      "[58]\ttraining's multi_error: 0.0105943\ttraining's multi_logloss: 0.140273\tvalid_1's multi_error: 0.177497\tvalid_1's multi_logloss: 0.563638\n",
      "[59]\ttraining's multi_error: 0.0103359\ttraining's multi_logloss: 0.136236\tvalid_1's multi_error: 0.178099\tvalid_1's multi_logloss: 0.562439\n",
      "[60]\ttraining's multi_error: 0.00994832\ttraining's multi_logloss: 0.132332\tvalid_1's multi_error: 0.178099\tvalid_1's multi_logloss: 0.561218\n",
      "[61]\ttraining's multi_error: 0.00878553\ttraining's multi_logloss: 0.128546\tvalid_1's multi_error: 0.175692\tvalid_1's multi_logloss: 0.55989\n",
      "[62]\ttraining's multi_error: 0.00813953\ttraining's multi_logloss: 0.125074\tvalid_1's multi_error: 0.178099\tvalid_1's multi_logloss: 0.558718\n",
      "[63]\ttraining's multi_error: 0.00723514\ttraining's multi_logloss: 0.121717\tvalid_1's multi_error: 0.17509\tvalid_1's multi_logloss: 0.558519\n",
      "[64]\ttraining's multi_error: 0.00671835\ttraining's multi_logloss: 0.118272\tvalid_1's multi_error: 0.172684\tvalid_1's multi_logloss: 0.557324\n",
      "[65]\ttraining's multi_error: 0.00555556\ttraining's multi_logloss: 0.115358\tvalid_1's multi_error: 0.173285\tvalid_1's multi_logloss: 0.55649\n",
      "[66]\ttraining's multi_error: 0.00516796\ttraining's multi_logloss: 0.11207\tvalid_1's multi_error: 0.174489\tvalid_1's multi_logloss: 0.555418\n",
      "[67]\ttraining's multi_error: 0.00490956\ttraining's multi_logloss: 0.109198\tvalid_1's multi_error: 0.173887\tvalid_1's multi_logloss: 0.554349\n",
      "[68]\ttraining's multi_error: 0.00465116\ttraining's multi_logloss: 0.106316\tvalid_1's multi_error: 0.173887\tvalid_1's multi_logloss: 0.552971\n",
      "[69]\ttraining's multi_error: 0.00452196\ttraining's multi_logloss: 0.103565\tvalid_1's multi_error: 0.17509\tvalid_1's multi_logloss: 0.552384\n",
      "[70]\ttraining's multi_error: 0.00439276\ttraining's multi_logloss: 0.100824\tvalid_1's multi_error: 0.176294\tvalid_1's multi_logloss: 0.552342\n",
      "[71]\ttraining's multi_error: 0.00413437\ttraining's multi_logloss: 0.098405\tvalid_1's multi_error: 0.174489\tvalid_1's multi_logloss: 0.551116\n",
      "[72]\ttraining's multi_error: 0.00374677\ttraining's multi_logloss: 0.0961015\tvalid_1's multi_error: 0.174489\tvalid_1's multi_logloss: 0.550364\n",
      "[73]\ttraining's multi_error: 0.00335917\ttraining's multi_logloss: 0.0937169\tvalid_1's multi_error: 0.173285\tvalid_1's multi_logloss: 0.549834\n",
      "[74]\ttraining's multi_error: 0.00322997\ttraining's multi_logloss: 0.0915765\tvalid_1's multi_error: 0.173285\tvalid_1's multi_logloss: 0.54914\n",
      "[75]\ttraining's multi_error: 0.00297158\ttraining's multi_logloss: 0.0893395\tvalid_1's multi_error: 0.17509\tvalid_1's multi_logloss: 0.548067\n",
      "[76]\ttraining's multi_error: 0.00284238\ttraining's multi_logloss: 0.0873387\tvalid_1's multi_error: 0.175692\tvalid_1's multi_logloss: 0.547105\n",
      "[77]\ttraining's multi_error: 0.00232558\ttraining's multi_logloss: 0.0853542\tvalid_1's multi_error: 0.17509\tvalid_1's multi_logloss: 0.546255\n",
      "[78]\ttraining's multi_error: 0.00219638\ttraining's multi_logloss: 0.0833859\tvalid_1's multi_error: 0.173887\tvalid_1's multi_logloss: 0.546372\n",
      "[79]\ttraining's multi_error: 0.00219638\ttraining's multi_logloss: 0.0815054\tvalid_1's multi_error: 0.173285\tvalid_1's multi_logloss: 0.545774\n",
      "[80]\ttraining's multi_error: 0.00206718\ttraining's multi_logloss: 0.0797428\tvalid_1's multi_error: 0.172684\tvalid_1's multi_logloss: 0.545696\n",
      "[81]\ttraining's multi_error: 0.00193798\ttraining's multi_logloss: 0.0781181\tvalid_1's multi_error: 0.173887\tvalid_1's multi_logloss: 0.545108\n",
      "[82]\ttraining's multi_error: 0.00180879\ttraining's multi_logloss: 0.0764752\tvalid_1's multi_error: 0.173887\tvalid_1's multi_logloss: 0.544315\n",
      "[83]\ttraining's multi_error: 0.00167959\ttraining's multi_logloss: 0.0748061\tvalid_1's multi_error: 0.173887\tvalid_1's multi_logloss: 0.54364\n",
      "[84]\ttraining's multi_error: 0.00155039\ttraining's multi_logloss: 0.0732411\tvalid_1's multi_error: 0.172684\tvalid_1's multi_logloss: 0.543105\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttraining's multi_error: 0.00671835\ttraining's multi_logloss: 0.118272\tvalid_1's multi_error: 0.172684\tvalid_1's multi_logloss: 0.557324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=LGBMClassifier(), n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': [0.01, 0.015, 0.025,\n",
       "                                                          0.05, 0.1],\n",
       "                                        'max_depth': [3, 5, 7, 9, 12, 15, 17,\n",
       "                                                      25],\n",
       "                                        'min_child_weight': [1, 3, 5, 7],\n",
       "                                        'subsample': array([0.6, 0.7, 0.8, 0.9, 1. ])},\n",
       "                   return_train_score=True, scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_clf = lgbm.LGBMClassifier()\n",
    "\n",
    "lgbm_param_grid = {'learning_rate': [.01, .015, .025, .05, .1],\n",
    "#                   'Gamma': [.05, .1, .3, .5, .7, .9, 1],\n",
    "                  'max_depth': [3, 5, 7, 9, 12, 15, 17, 25],\n",
    "                  'min_child_weight': [1, 3, 5, 7],\n",
    "                  'subsample': np.linspace(0.6, 1, 5)}\n",
    "\n",
    "fit_params = {\"early_stopping_rounds\" : 20,\n",
    "             \"eval_metric\" : \"multi_error\",\n",
    "             \"eval_set\" : [(X_train, y_train), (X_val, y_val)]}\n",
    "\n",
    "# Create a random search object\n",
    "lgbm_random = RandomizedSearchCV(estimator = lgbm_clf,\n",
    "                                param_distributions = lgbm_param_grid,\n",
    "                                n_iter = 20, # n_iters in param combinations\n",
    "                                scoring='accuracy',\n",
    "                                n_jobs=-1,\n",
    "                                cv = 5,\n",
    "                                refit=True,\n",
    "                                return_train_score = True,\n",
    "                                verbose=10)\n",
    "\n",
    "# Fit to the training data\n",
    "lgbm_random.fit(X_train, y_train, **fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = lgbm_random.best_estimator_.predict(X_train)\n",
    "pred_val = lgbm_random.best_estimator_.predict(X_val)\n",
    "pred_test = lgbm_random.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99328165374677\n",
      "0.8273164861612515\n",
      "0.812687013764213\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_train, pred_train))\n",
    "print(accuracy_score(y_val, pred_val))\n",
    "print(accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subsample</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.730620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.759302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.759302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.771447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.771964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.779587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.783075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.783075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.784755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.789018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.789018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.790310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.794057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.799354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.801034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.801292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.803488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.805426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.806589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.807235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subsample  min_child_weight  max_depth  learning_rate  mean_test_score\n",
       "0        0.7                 7          3          0.010         0.730620\n",
       "0        0.9                 3          3          0.025         0.759302\n",
       "0        0.7                 3          3          0.025         0.759302\n",
       "0        0.9                 7          7          0.010         0.771447\n",
       "0        1.0                 7         17          0.010         0.771964\n",
       "0        0.8                 7          9          0.015         0.779587\n",
       "0        0.7                 1         15          0.015         0.783075\n",
       "0        1.0                 1         15          0.015         0.783075\n",
       "0        0.9                 1          9          0.015         0.784755\n",
       "0        0.7                 7         17          0.025         0.789018\n",
       "0        0.6                 7         17          0.025         0.789018\n",
       "0        0.9                 3         25          0.025         0.790310\n",
       "0        0.7                 3          9          0.025         0.794057\n",
       "0        0.9                 5          5          0.050         0.799354\n",
       "0        0.8                 7          9          0.050         0.801034\n",
       "0        0.6                 3         17          0.050         0.801292\n",
       "0        0.6                 3          9          0.050         0.803488\n",
       "0        0.6                 5         17          0.100         0.805426\n",
       "0        0.8                 7         17          0.100         0.806589\n",
       "0        0.6                 5         15          0.100         0.807235"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_df = pd.DataFrame(lgbm_random.cv_results_)\n",
    "\n",
    "df_list = []\n",
    "for i in range(20):\n",
    "    df_list.append(pd.DataFrame([cv_result_df.loc[i, \"params\"]]))\n",
    "    \n",
    "param_table = pd.concat(df_list)\n",
    "\n",
    "param_table['mean_test_score'] = cv_result_df['mean_test_score'].values\n",
    "\n",
    "param_table.sort_values(by='mean_test_score', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
