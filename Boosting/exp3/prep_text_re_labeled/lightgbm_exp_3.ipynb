{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(4444)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>dataset_n</th>\n",
       "      <th>prep_v9_text</th>\n",
       "      <th>label_2</th>\n",
       "      <th>train_val_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R1508073.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>보 도 자 료\\nhttp://www.motie.go.kr\\n2015년 8월 5일(수...</td>\n",
       "      <td>0</td>\n",
       "      <td>이후N 가능N 문의N 산업N 스마트N 공장N 재부N 산업N 정보N 예산N 과장N 스...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D2006211.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>보도일시 2020. 6. 24.(수) 조간(온라인 6. 23. 16:00)부터 보도...</td>\n",
       "      <td>0</td>\n",
       "      <td>온라인N 과학N 기술N 정보N 협력N 산업N 통상N 자원N 산업N 기술N 개발N 과...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D2006529.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>기획조정관             과 장  김용훈   ...</td>\n",
       "      <td>0</td>\n",
       "      <td>기획N 혁신N 행정관N 이후N 게재N 특허청N 지식N 재산N 정책N 공개N 국민N ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D2001017.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>2020년 1월 30일(목) 석간부터 보도하여 주시기 바랍니다. * 통신․방송․인터...</td>\n",
       "      <td>0</td>\n",
       "      <td>이후N 가능N 문의N 창업N 촉진N 기훈N 과장N 정착N 그랜드N 챌린지N 스타트업...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R2007307.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>과    장    최병석 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>특허N 사업N 화관N 이후N 특허청N 지역N 창업N 기업N 지원N 온라인N line...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_name  label                                           raw_text  \\\n",
       "0  R1508073.txt      0  보 도 자 료\\nhttp://www.motie.go.kr\\n2015년 8월 5일(수...   \n",
       "1  D2006211.txt      0  보도일시 2020. 6. 24.(수) 조간(온라인 6. 23. 16:00)부터 보도...   \n",
       "2  D2006529.txt      0                   기획조정관             과 장  김용훈   ...   \n",
       "3  D2001017.txt      0  2020년 1월 30일(목) 석간부터 보도하여 주시기 바랍니다. * 통신․방송․인터...   \n",
       "4  R2007307.txt      0                                  과    장    최병석 ...   \n",
       "\n",
       "   dataset_n                                       prep_v9_text  label_2  \\\n",
       "0          0  이후N 가능N 문의N 산업N 스마트N 공장N 재부N 산업N 정보N 예산N 과장N 스...        0   \n",
       "1          0  온라인N 과학N 기술N 정보N 협력N 산업N 통상N 자원N 산업N 기술N 개발N 과...        0   \n",
       "2          0  기획N 혁신N 행정관N 이후N 게재N 특허청N 지식N 재산N 정책N 공개N 국민N ...        0   \n",
       "3          0  이후N 가능N 문의N 창업N 촉진N 기훈N 과장N 정착N 그랜드N 챌린지N 스타트업...        0   \n",
       "4          0  특허N 사업N 화관N 이후N 특허청N 지역N 창업N 기업N 지원N 온라인N line...        0   \n",
       "\n",
       "   train_val_test  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../../../../../jaeyeun/01_nh_poc/16_re_label/split_70_15_15_re_1.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* exp3 combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = df[df['train_val_test'] == 0]\n",
    "X_val_df = df[df['train_val_test'] == 1]\n",
    "X_test_df = df[df['train_val_test'] == 2]\n",
    "y_train = df[df['train_val_test'] == 0]['label_2']\n",
    "y_val = df[df['train_val_test'] == 1]['label_2']\n",
    "y_test = df[df['train_val_test'] == 2]['label_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7742, 7)\n",
      "(1659, 7)\n",
      "(1672, 7)\n",
      "(7742,)\n",
      "(1659,)\n",
      "(1672,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_df.shape)\n",
    "print(X_val_df.shape)\n",
    "print(X_test_df.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 100000\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_df=0.9, # 0.9 만큼의 문서 이상에서 나오면 거른다.\n",
    "    min_df=5, # 5개 미만의 문서에서 나오면 거른다.\n",
    "    sublinear_tf = True, # tf value를 완만하게 처리 (outlier 처리 효과)\n",
    "    ngram_range = (1, 3),\n",
    "    max_features=n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* data is 'prep_v9_text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf_vectorizer.fit(X_train_df['prep_v9_text'])\n",
    "# X_test_tfidf = tfidf_vectorizer.fit_transform(prep_text_test)\n",
    "# X_test_hash = hash_vectorizer.fit_transform(prep_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_tfidf.transform(X_train_df['prep_v9_text'])\n",
    "X_val = X_train_tfidf.transform(X_val_df['prep_v9_text'])\n",
    "X_test = X_train_tfidf.transform(X_test_df['prep_v9_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7742, 100000)\n",
      "(1659, 100000)\n",
      "(1672, 100000)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* LightGBM RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed: 16.0min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed: 29.9min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 35.4min\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of 100 | elapsed: 47.0min remaining: 50.9min\n",
      "[Parallel(n_jobs=-1)]: Done  59 out of 100 | elapsed: 53.4min remaining: 37.1min\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of 100 | elapsed: 59.1min remaining: 25.3min\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of 100 | elapsed: 62.7min remaining: 14.7min\n",
      "[Parallel(n_jobs=-1)]: Done  92 out of 100 | elapsed: 69.5min remaining:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 77.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's multi_error: 0.352105\ttraining's multi_logloss: 1.93514\tvalid_1's multi_error: 0.403858\tvalid_1's multi_logloss: 1.96338\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\ttraining's multi_error: 0.177732\ttraining's multi_logloss: 1.70996\tvalid_1's multi_error: 0.278481\tvalid_1's multi_logloss: 1.76241\n",
      "[3]\ttraining's multi_error: 0.132524\ttraining's multi_logloss: 1.53565\tvalid_1's multi_error: 0.238698\tvalid_1's multi_logloss: 1.61238\n",
      "[4]\ttraining's multi_error: 0.117541\ttraining's multi_logloss: 1.39378\tvalid_1's multi_error: 0.223629\tvalid_1's multi_logloss: 1.49014\n",
      "[5]\ttraining's multi_error: 0.107207\ttraining's multi_logloss: 1.27388\tvalid_1's multi_error: 0.213382\tvalid_1's multi_logloss: 1.38767\n",
      "[6]\ttraining's multi_error: 0.100491\ttraining's multi_logloss: 1.17129\tvalid_1's multi_error: 0.201929\tvalid_1's multi_logloss: 1.30036\n",
      "[7]\ttraining's multi_error: 0.0962284\ttraining's multi_logloss: 1.08136\tvalid_1's multi_error: 0.199518\tvalid_1's multi_logloss: 1.22389\n",
      "[8]\ttraining's multi_error: 0.0878326\ttraining's multi_logloss: 1.00198\tvalid_1's multi_error: 0.192285\tvalid_1's multi_logloss: 1.1576\n",
      "[9]\ttraining's multi_error: 0.0836993\ttraining's multi_logloss: 0.93103\tvalid_1's multi_error: 0.185654\tvalid_1's multi_logloss: 1.09837\n",
      "[10]\ttraining's multi_error: 0.0796952\ttraining's multi_logloss: 0.868146\tvalid_1's multi_error: 0.185051\tvalid_1's multi_logloss: 1.04794\n",
      "[11]\ttraining's multi_error: 0.0743994\ttraining's multi_logloss: 0.811285\tvalid_1's multi_error: 0.18264\tvalid_1's multi_logloss: 1.00043\n",
      "[12]\ttraining's multi_error: 0.0718161\ttraining's multi_logloss: 0.760047\tvalid_1's multi_error: 0.179626\tvalid_1's multi_logloss: 0.958624\n",
      "[13]\ttraining's multi_error: 0.0694911\ttraining's multi_logloss: 0.713121\tvalid_1's multi_error: 0.178421\tvalid_1's multi_logloss: 0.919776\n",
      "[14]\ttraining's multi_error: 0.0663911\ttraining's multi_logloss: 0.670402\tvalid_1's multi_error: 0.17601\tvalid_1's multi_logloss: 0.88594\n",
      "[15]\ttraining's multi_error: 0.063937\ttraining's multi_logloss: 0.631076\tvalid_1's multi_error: 0.177818\tvalid_1's multi_logloss: 0.855064\n",
      "[16]\ttraining's multi_error: 0.0613537\ttraining's multi_logloss: 0.595325\tvalid_1's multi_error: 0.177818\tvalid_1's multi_logloss: 0.826729\n",
      "[17]\ttraining's multi_error: 0.0601912\ttraining's multi_logloss: 0.562146\tvalid_1's multi_error: 0.176612\tvalid_1's multi_logloss: 0.801026\n",
      "[18]\ttraining's multi_error: 0.0579954\ttraining's multi_logloss: 0.531841\tvalid_1's multi_error: 0.178421\tvalid_1's multi_logloss: 0.778585\n",
      "[19]\ttraining's multi_error: 0.0555412\ttraining's multi_logloss: 0.503712\tvalid_1's multi_error: 0.177215\tvalid_1's multi_logloss: 0.757342\n",
      "[20]\ttraining's multi_error: 0.0541204\ttraining's multi_logloss: 0.477492\tvalid_1's multi_error: 0.179626\tvalid_1's multi_logloss: 0.737155\n",
      "[21]\ttraining's multi_error: 0.0516662\ttraining's multi_logloss: 0.453076\tvalid_1's multi_error: 0.177818\tvalid_1's multi_logloss: 0.71863\n",
      "[22]\ttraining's multi_error: 0.0486954\ttraining's multi_logloss: 0.430118\tvalid_1's multi_error: 0.17601\tvalid_1's multi_logloss: 0.70174\n",
      "[23]\ttraining's multi_error: 0.0470163\ttraining's multi_logloss: 0.408737\tvalid_1's multi_error: 0.171187\tvalid_1's multi_logloss: 0.686638\n",
      "[24]\ttraining's multi_error: 0.0443038\ttraining's multi_logloss: 0.388612\tvalid_1's multi_error: 0.175407\tvalid_1's multi_logloss: 0.671248\n",
      "[25]\ttraining's multi_error: 0.0422371\ttraining's multi_logloss: 0.370131\tvalid_1's multi_error: 0.172996\tvalid_1's multi_logloss: 0.658298\n",
      "[26]\ttraining's multi_error: 0.040558\ttraining's multi_logloss: 0.352481\tvalid_1's multi_error: 0.169982\tvalid_1's multi_logloss: 0.64529\n",
      "[27]\ttraining's multi_error: 0.0373289\ttraining's multi_logloss: 0.335997\tvalid_1's multi_error: 0.169982\tvalid_1's multi_logloss: 0.632435\n",
      "[28]\ttraining's multi_error: 0.0350039\ttraining's multi_logloss: 0.320618\tvalid_1's multi_error: 0.167571\tvalid_1's multi_logloss: 0.621547\n",
      "[29]\ttraining's multi_error: 0.0321622\ttraining's multi_logloss: 0.306114\tvalid_1's multi_error: 0.170585\tvalid_1's multi_logloss: 0.61091\n",
      "[30]\ttraining's multi_error: 0.0304831\ttraining's multi_logloss: 0.292464\tvalid_1's multi_error: 0.171187\tvalid_1's multi_logloss: 0.600774\n",
      "[31]\ttraining's multi_error: 0.0295789\ttraining's multi_logloss: 0.279443\tvalid_1's multi_error: 0.169982\tvalid_1's multi_logloss: 0.592004\n",
      "[32]\ttraining's multi_error: 0.0282873\ttraining's multi_logloss: 0.267082\tvalid_1's multi_error: 0.167571\tvalid_1's multi_logloss: 0.583574\n",
      "[33]\ttraining's multi_error: 0.0269956\ttraining's multi_logloss: 0.255431\tvalid_1's multi_error: 0.168174\tvalid_1's multi_logloss: 0.575953\n",
      "[34]\ttraining's multi_error: 0.025704\ttraining's multi_logloss: 0.244505\tvalid_1's multi_error: 0.168776\tvalid_1's multi_logloss: 0.56856\n",
      "[35]\ttraining's multi_error: 0.0247998\ttraining's multi_logloss: 0.234167\tvalid_1's multi_error: 0.166968\tvalid_1's multi_logloss: 0.561066\n",
      "[36]\ttraining's multi_error: 0.0232498\ttraining's multi_logloss: 0.22452\tvalid_1's multi_error: 0.167571\tvalid_1's multi_logloss: 0.555507\n",
      "[37]\ttraining's multi_error: 0.0223456\ttraining's multi_logloss: 0.215283\tvalid_1's multi_error: 0.168174\tvalid_1's multi_logloss: 0.549601\n",
      "[38]\ttraining's multi_error: 0.0196332\ttraining's multi_logloss: 0.206501\tvalid_1's multi_error: 0.166365\tvalid_1's multi_logloss: 0.543299\n",
      "[39]\ttraining's multi_error: 0.0188582\ttraining's multi_logloss: 0.198216\tvalid_1's multi_error: 0.167571\tvalid_1's multi_logloss: 0.538724\n",
      "[40]\ttraining's multi_error: 0.0176957\ttraining's multi_logloss: 0.190312\tvalid_1's multi_error: 0.164557\tvalid_1's multi_logloss: 0.533303\n",
      "[41]\ttraining's multi_error: 0.0166624\ttraining's multi_logloss: 0.182714\tvalid_1's multi_error: 0.163954\tvalid_1's multi_logloss: 0.528909\n",
      "[42]\ttraining's multi_error: 0.015629\ttraining's multi_logloss: 0.175628\tvalid_1's multi_error: 0.16516\tvalid_1's multi_logloss: 0.524895\n",
      "[43]\ttraining's multi_error: 0.0149832\ttraining's multi_logloss: 0.168914\tvalid_1's multi_error: 0.163954\tvalid_1's multi_logloss: 0.520497\n",
      "[44]\ttraining's multi_error: 0.0134332\ttraining's multi_logloss: 0.162486\tvalid_1's multi_error: 0.163351\tvalid_1's multi_logloss: 0.517331\n",
      "[45]\ttraining's multi_error: 0.0126582\ttraining's multi_logloss: 0.156373\tvalid_1's multi_error: 0.16516\tvalid_1's multi_logloss: 0.513823\n",
      "[46]\ttraining's multi_error: 0.0116249\ttraining's multi_logloss: 0.150428\tvalid_1's multi_error: 0.165763\tvalid_1's multi_logloss: 0.510435\n",
      "[47]\ttraining's multi_error: 0.0112374\ttraining's multi_logloss: 0.14481\tvalid_1's multi_error: 0.165763\tvalid_1's multi_logloss: 0.506774\n",
      "[48]\ttraining's multi_error: 0.0103332\ttraining's multi_logloss: 0.139423\tvalid_1's multi_error: 0.166365\tvalid_1's multi_logloss: 0.503694\n",
      "[49]\ttraining's multi_error: 0.00955825\ttraining's multi_logloss: 0.134376\tvalid_1's multi_error: 0.164557\tvalid_1's multi_logloss: 0.501056\n",
      "[50]\ttraining's multi_error: 0.00929992\ttraining's multi_logloss: 0.129525\tvalid_1's multi_error: 0.16516\tvalid_1's multi_logloss: 0.49867\n",
      "[51]\ttraining's multi_error: 0.00813743\ttraining's multi_logloss: 0.124863\tvalid_1's multi_error: 0.163954\tvalid_1's multi_logloss: 0.496179\n",
      "[52]\ttraining's multi_error: 0.00774994\ttraining's multi_logloss: 0.120544\tvalid_1's multi_error: 0.162749\tvalid_1's multi_logloss: 0.494312\n",
      "[53]\ttraining's multi_error: 0.00684578\ttraining's multi_logloss: 0.116356\tvalid_1's multi_error: 0.16516\tvalid_1's multi_logloss: 0.492758\n",
      "[54]\ttraining's multi_error: 0.00645828\ttraining's multi_logloss: 0.112275\tvalid_1's multi_error: 0.163351\tvalid_1's multi_logloss: 0.490254\n",
      "[55]\ttraining's multi_error: 0.00632911\ttraining's multi_logloss: 0.108423\tvalid_1's multi_error: 0.163351\tvalid_1's multi_logloss: 0.487501\n",
      "[56]\ttraining's multi_error: 0.00581245\ttraining's multi_logloss: 0.104938\tvalid_1's multi_error: 0.162749\tvalid_1's multi_logloss: 0.486753\n",
      "[57]\ttraining's multi_error: 0.00542495\ttraining's multi_logloss: 0.101382\tvalid_1's multi_error: 0.162146\tvalid_1's multi_logloss: 0.484708\n",
      "[58]\ttraining's multi_error: 0.00542495\ttraining's multi_logloss: 0.098059\tvalid_1's multi_error: 0.162749\tvalid_1's multi_logloss: 0.48304\n",
      "[59]\ttraining's multi_error: 0.00464996\ttraining's multi_logloss: 0.0948565\tvalid_1's multi_error: 0.161543\tvalid_1's multi_logloss: 0.480795\n",
      "[60]\ttraining's multi_error: 0.00439163\ttraining's multi_logloss: 0.0919408\tvalid_1's multi_error: 0.16094\tvalid_1's multi_logloss: 0.479513\n",
      "[61]\ttraining's multi_error: 0.00387497\ttraining's multi_logloss: 0.0890878\tvalid_1's multi_error: 0.160338\tvalid_1's multi_logloss: 0.478107\n",
      "[62]\ttraining's multi_error: 0.00322914\ttraining's multi_logloss: 0.0862249\tvalid_1's multi_error: 0.16094\tvalid_1's multi_logloss: 0.475767\n",
      "[63]\ttraining's multi_error: 0.00297081\ttraining's multi_logloss: 0.083638\tvalid_1's multi_error: 0.159735\tvalid_1's multi_logloss: 0.473554\n",
      "[64]\ttraining's multi_error: 0.00271248\ttraining's multi_logloss: 0.0811823\tvalid_1's multi_error: 0.16094\tvalid_1's multi_logloss: 0.473272\n",
      "[65]\ttraining's multi_error: 0.00232498\ttraining's multi_logloss: 0.078821\tvalid_1's multi_error: 0.16094\tvalid_1's multi_logloss: 0.47247\n",
      "[66]\ttraining's multi_error: 0.00206665\ttraining's multi_logloss: 0.0765616\tvalid_1's multi_error: 0.159735\tvalid_1's multi_logloss: 0.471033\n",
      "[67]\ttraining's multi_error: 0.00206665\ttraining's multi_logloss: 0.0742675\tvalid_1's multi_error: 0.157926\tvalid_1's multi_logloss: 0.469571\n",
      "[68]\ttraining's multi_error: 0.00180832\ttraining's multi_logloss: 0.0722114\tvalid_1's multi_error: 0.159735\tvalid_1's multi_logloss: 0.468842\n",
      "[69]\ttraining's multi_error: 0.00167915\ttraining's multi_logloss: 0.0702389\tvalid_1's multi_error: 0.157324\tvalid_1's multi_logloss: 0.467982\n",
      "[70]\ttraining's multi_error: 0.00167915\ttraining's multi_logloss: 0.0683771\tvalid_1's multi_error: 0.156721\tvalid_1's multi_logloss: 0.466748\n",
      "[71]\ttraining's multi_error: 0.00167915\ttraining's multi_logloss: 0.0665253\tvalid_1's multi_error: 0.156118\tvalid_1's multi_logloss: 0.465598\n",
      "[72]\ttraining's multi_error: 0.00167915\ttraining's multi_logloss: 0.0647757\tvalid_1's multi_error: 0.157324\tvalid_1's multi_logloss: 0.46468\n",
      "[73]\ttraining's multi_error: 0.00142082\ttraining's multi_logloss: 0.063064\tvalid_1's multi_error: 0.156721\tvalid_1's multi_logloss: 0.463749\n",
      "[74]\ttraining's multi_error: 0.00129166\ttraining's multi_logloss: 0.0614514\tvalid_1's multi_error: 0.155515\tvalid_1's multi_logloss: 0.463361\n",
      "[75]\ttraining's multi_error: 0.00129166\ttraining's multi_logloss: 0.0599298\tvalid_1's multi_error: 0.156721\tvalid_1's multi_logloss: 0.462736\n",
      "[76]\ttraining's multi_error: 0.00129166\ttraining's multi_logloss: 0.0585114\tvalid_1's multi_error: 0.156721\tvalid_1's multi_logloss: 0.461402\n",
      "[77]\ttraining's multi_error: 0.00129166\ttraining's multi_logloss: 0.0571149\tvalid_1's multi_error: 0.156721\tvalid_1's multi_logloss: 0.46118\n",
      "[78]\ttraining's multi_error: 0.00116249\ttraining's multi_logloss: 0.0557409\tvalid_1's multi_error: 0.157324\tvalid_1's multi_logloss: 0.46036\n",
      "[79]\ttraining's multi_error: 0.00103332\ttraining's multi_logloss: 0.0545331\tvalid_1's multi_error: 0.157324\tvalid_1's multi_logloss: 0.459389\n",
      "[80]\ttraining's multi_error: 0.00103332\ttraining's multi_logloss: 0.0533048\tvalid_1's multi_error: 0.157324\tvalid_1's multi_logloss: 0.4594\n",
      "[81]\ttraining's multi_error: 0.00103332\ttraining's multi_logloss: 0.0521341\tvalid_1's multi_error: 0.156118\tvalid_1's multi_logloss: 0.458674\n",
      "[82]\ttraining's multi_error: 0.000904159\ttraining's multi_logloss: 0.0509932\tvalid_1's multi_error: 0.156118\tvalid_1's multi_logloss: 0.458337\n",
      "[83]\ttraining's multi_error: 0.000904159\ttraining's multi_logloss: 0.0498862\tvalid_1's multi_error: 0.156721\tvalid_1's multi_logloss: 0.45836\n",
      "[84]\ttraining's multi_error: 0.000904159\ttraining's multi_logloss: 0.0488181\tvalid_1's multi_error: 0.156721\tvalid_1's multi_logloss: 0.457949\n",
      "[85]\ttraining's multi_error: 0.000904159\ttraining's multi_logloss: 0.0478487\tvalid_1's multi_error: 0.157324\tvalid_1's multi_logloss: 0.457681\n",
      "[86]\ttraining's multi_error: 0.000904159\ttraining's multi_logloss: 0.0469221\tvalid_1's multi_error: 0.156721\tvalid_1's multi_logloss: 0.457449\n",
      "[87]\ttraining's multi_error: 0.000904159\ttraining's multi_logloss: 0.0459954\tvalid_1's multi_error: 0.156721\tvalid_1's multi_logloss: 0.457725\n",
      "[88]\ttraining's multi_error: 0.000904159\ttraining's multi_logloss: 0.0451414\tvalid_1's multi_error: 0.157324\tvalid_1's multi_logloss: 0.457136\n",
      "[89]\ttraining's multi_error: 0.000774994\ttraining's multi_logloss: 0.0442985\tvalid_1's multi_error: 0.157324\tvalid_1's multi_logloss: 0.45689\n",
      "[90]\ttraining's multi_error: 0.000774994\ttraining's multi_logloss: 0.0434982\tvalid_1's multi_error: 0.156721\tvalid_1's multi_logloss: 0.456938\n",
      "[91]\ttraining's multi_error: 0.000774994\ttraining's multi_logloss: 0.0427294\tvalid_1's multi_error: 0.156721\tvalid_1's multi_logloss: 0.456447\n",
      "[92]\ttraining's multi_error: 0.000774994\ttraining's multi_logloss: 0.0419683\tvalid_1's multi_error: 0.156118\tvalid_1's multi_logloss: 0.456446\n",
      "[93]\ttraining's multi_error: 0.000774994\ttraining's multi_logloss: 0.0412551\tvalid_1's multi_error: 0.156721\tvalid_1's multi_logloss: 0.455607\n",
      "[94]\ttraining's multi_error: 0.000774994\ttraining's multi_logloss: 0.0405326\tvalid_1's multi_error: 0.154913\tvalid_1's multi_logloss: 0.454993\n",
      "[95]\ttraining's multi_error: 0.000774994\ttraining's multi_logloss: 0.0398163\tvalid_1's multi_error: 0.154913\tvalid_1's multi_logloss: 0.454819\n",
      "[96]\ttraining's multi_error: 0.000774994\ttraining's multi_logloss: 0.0391886\tvalid_1's multi_error: 0.155515\tvalid_1's multi_logloss: 0.454791\n",
      "[97]\ttraining's multi_error: 0.000774994\ttraining's multi_logloss: 0.0385329\tvalid_1's multi_error: 0.156118\tvalid_1's multi_logloss: 0.454749\n",
      "[98]\ttraining's multi_error: 0.000774994\ttraining's multi_logloss: 0.0379113\tvalid_1's multi_error: 0.156721\tvalid_1's multi_logloss: 0.454762\n",
      "[99]\ttraining's multi_error: 0.000774994\ttraining's multi_logloss: 0.0373239\tvalid_1's multi_error: 0.156118\tvalid_1's multi_logloss: 0.454736\n",
      "[100]\ttraining's multi_error: 0.000774994\ttraining's multi_logloss: 0.0367353\tvalid_1's multi_error: 0.155515\tvalid_1's multi_logloss: 0.454777\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[89]\ttraining's multi_error: 0.000774994\ttraining's multi_logloss: 0.0442985\tvalid_1's multi_error: 0.157324\tvalid_1's multi_logloss: 0.45689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=LGBMClassifier(), n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': [0.01, 0.015, 0.025,\n",
       "                                                          0.05, 0.1],\n",
       "                                        'max_depth': [3, 5, 7, 9, 12, 15, 17,\n",
       "                                                      25],\n",
       "                                        'min_child_weight': [1, 3, 5, 7],\n",
       "                                        'subsample': array([0.6, 0.7, 0.8, 0.9, 1. ])},\n",
       "                   return_train_score=True, scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_clf = lgbm.LGBMClassifier()\n",
    "\n",
    "lgbm_param_grid = {'learning_rate': [.01, .015, .025, .05, .1],\n",
    "#                   'Gamma': [.05, .1, .3, .5, .7, .9, 1],\n",
    "                  'max_depth': [3, 5, 7, 9, 12, 15, 17, 25],\n",
    "                  'min_child_weight': [1, 3, 5, 7],\n",
    "                  'subsample': np.linspace(0.6, 1, 5)}\n",
    "\n",
    "fit_params = {\"early_stopping_rounds\" : 20,\n",
    "             \"eval_metric\" : \"multi_error\",\n",
    "             \"eval_set\" : [(X_train, y_train), (X_val, y_val)]}\n",
    "\n",
    "# Create a random search object\n",
    "lgbm_random = RandomizedSearchCV(estimator = lgbm_clf,\n",
    "                                param_distributions = lgbm_param_grid,\n",
    "                                n_iter = 20, # n_iters in param combinations\n",
    "                                scoring='accuracy',\n",
    "                                n_jobs=-1,\n",
    "                                cv = 5,\n",
    "                                refit=True,\n",
    "                                return_train_score = True,\n",
    "                                verbose=10)\n",
    "\n",
    "# Fit to the training data\n",
    "lgbm_random.fit(X_train, y_train, **fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = lgbm_random.best_estimator_.predict(X_train)\n",
    "pred_val = lgbm_random.best_estimator_.predict(X_val)\n",
    "pred_test = lgbm_random.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9992250064582795\n",
      "0.8426763110307414\n",
      "0.8588516746411483\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_train, pred_train))\n",
    "print(accuracy_score(y_val, pred_val))\n",
    "print(accuracy_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subsample</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.807798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.810123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.811802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.812190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.812190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.812967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.814772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.816323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.822137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.822265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.824850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.826914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.828079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.829369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.829629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.832472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.835311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.835439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.838667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.849518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subsample  min_child_weight  max_depth  learning_rate  mean_test_score\n",
       "0        0.7                 1          7          0.010         0.807798\n",
       "0        0.9                 1         25          0.010         0.810123\n",
       "0        0.6                 7         25          0.010         0.811802\n",
       "0        0.9                 3         12          0.010         0.812190\n",
       "0        0.7                 3         12          0.010         0.812190\n",
       "0        0.7                 3          7          0.015         0.812967\n",
       "0        1.0                 7         12          0.015         0.814772\n",
       "0        0.8                 5          9          0.015         0.816323\n",
       "0        1.0                 7         12          0.025         0.822137\n",
       "0        1.0                 3          9          0.015         0.822265\n",
       "0        0.6                 7         15          0.025         0.824850\n",
       "0        1.0                 5         15          0.025         0.826914\n",
       "0        0.7                 5          9          0.025         0.828079\n",
       "0        0.9                 1         25          0.025         0.829369\n",
       "0        0.9                 5          7          0.050         0.829629\n",
       "0        0.9                 5         15          0.050         0.832472\n",
       "0        0.8                 1          7          0.050         0.835311\n",
       "0        0.6                 3          7          0.050         0.835439\n",
       "0        0.6                 1          5          0.100         0.838667\n",
       "0        0.6                 5         17          0.100         0.849518"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_df = pd.DataFrame(lgbm_random.cv_results_)\n",
    "\n",
    "df_list = []\n",
    "for i in range(20):\n",
    "    df_list.append(pd.DataFrame([cv_result_df.loc[i, \"params\"]]))\n",
    "    \n",
    "param_table = pd.concat(df_list)\n",
    "\n",
    "param_table['mean_test_score'] = cv_result_df['mean_test_score'].values\n",
    "\n",
    "param_table.sort_values(by='mean_test_score', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
